{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Introduction to Apache Spark](http://spark.apache.org/) üéáüéá ‚ú®‚ú®"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://full-stack-assets.s3.eu-west-3.amazonaws.com/images/Apache_Spark_logo-f31fc9de-9456-4351-b459-2fe24f92628b.png\"></center>\n",
    "\n",
    "* Apache Spark in an open-source distributed cluster-computing system designed to be fast and general-purpose.\n",
    "* Created in 2009 at Berkeley's AMPLab by Matei Zaharia, the Spark codebase was donated in 2013 to the Apache Software Foundation. It has since become one of its most active projects.\n",
    "* Spark provides high-level APIs in `Scala`, `Java`, `Python` and `R` and an optimized execution engine. On top of this \n",
    "technology, sit higher-lever tools including `Spark SQL`, `MLlib`, `GraphX` and `Spark Streaming`.\n",
    "\n",
    "## What you will learn in this course üßêüßê\n",
    "This course will teach you some theory about the Spark framework, how it works and what advantages it has over other distributed computing frameworks. Here's the outline:\n",
    "\n",
    "* Apache Spark\n",
    "* Hadoop vs Spark\n",
    "    * Faster through In-Memory computation\n",
    "    * Simpler (high-level APIs) and execution engine optimisation\n",
    "* Need for a DFS (Distributed File System)\n",
    "* The Spark stack\n",
    "    * Spark Core - the main functionnalities of the framework\n",
    "    * Spark SQL - to handle structured data and run queries\n",
    "    * GraphX - The visualisation tool of Spark\n",
    "    * MLlib - The machine learning toolbox for Spark\n",
    "    * Spark Streaming - An API to handle continuous inflow of data\n",
    "\n",
    "* Spark's mechanics\n",
    "    * DAG (Directed Acyclic Graphs) scheduling\n",
    "    * Lazy execution\n",
    "        * Transformations\n",
    "        * Actions\n",
    "    * Mixed language\n",
    "* PySpark\n",
    "\n",
    "## Ressources üìöüìö\n",
    "* The [official spark documentation](http://spark.apache.org/docs/latest/)\n",
    "* [cluster-overview](https://spark.apache.org/docs/latest/cluster-overview.html)\n",
    "* Interesting notes on clusters: [https://jaceklaskowski.gitbooks.io/mastering-apache-spark/spark-cluster.html](https://jaceklaskowski.gitbooks.io/mastering-apache-spark/spark-cluster.html)\n",
    "* You can take a look at [Spark Basics : RDDs,Stages,Tasks and DAG](https://medium.com/@goyalsaurabh66/spark-basics-rdds-stages-tasks-and-dag-8da0f52f0454) but this covers concepts we haven't seen yet\n",
    "* [Debugging PySpark](https://www.youtube.com/watch?v=McgG09XriEI)\n",
    "- [What is Spark SQL](https://databricks.com/glossary/what-is-spark-sql)\n",
    "- [Deep dive into Spark SQL's Catalyst Optimizer](https://databricks.com/blog/2015/04/13/deep-dive-into-spark-sqls-catalyst-optimizer.html)\n",
    "- [SparkSqlAstBuilder](https://jaceklaskowski.gitbooks.io/mastering-spark-sql/spark-sql-SparkSqlAstBuilder.html)\n",
    "- [A Gentle Introduction to Stream Processing](https://medium.com/stream-processing/what-is-stream-processing-1eadfca11b97)\n",
    "\n",
    "\n",
    "## Hadoop vs Spark üêòüÜö‚ú®\n",
    "\n",
    "- **Faster through In-Memory computation** ‚ö° Because memory time access is much faster than disk access, Spark's In-Memory computation makes it much faster than Hadoop which relies on disk\n",
    "- **Simpler (high-level APIs) and execution engine optimisation üß∏ :** \n",
    "    * Spark's high-level APIs combined with lazy computation *means we don't have to optimize each query. Spark execution engine will take care of building an optimized physical execution plan.*\n",
    "    * Also, code you write in \"local\" mode will work on a cluster \"out-of-the-box\" thanks to Spark's higher level API.\n",
    "    * That doesn't mean it will be easy to write Spark code, but Spark makes it much easier to write optimized code that will run at big data scale.\n",
    "\n",
    "## The need for a distributed storage üîÄüîÄ\n",
    "\n",
    "* If compute is distributed, all the machine needs to have access to the data, without a distributed storage that would be **very tedious**.\n",
    "* Unlike Hadoop, Spark doesn't come with its own file system, but can interface with many existing ones, such as Hadoop Distributed File System (HDFS), Cassandra, Amazon S3 and many more...\n",
    "* Spark can supports a pseudo-distributed local mode (for development or testing purposes), in this case, Spark is run on a single machine with one executor per CPU core and a distributed file storage is not required.\n",
    "\n",
    "## The Spark Stack ‚ú®‚öôÔ∏è\n",
    "\n",
    "One of Spark's promises is to deliver a unified analytics system. On top of its powerful distributed processing engine (Spark Core), sits a collection of higher-level libraries that all benefit from the improvements of the core library, which are low latency, and lazy execution.\n",
    "\n",
    "*That's true in general, but can suffer from some caveats, in particular Spark Streaming's performances can't rival those of Storm and Flink which are other framework for running streaming jobs.*\n",
    "\n",
    "<center><img src=\"https://full-stack-assets.s3.eu-west-3.amazonaws.com/images/spark-stack-oreilly-674376df-ecdf-45f2-8ef7-539393568c0e.png\"></center>\n",
    "\n",
    "Source: Learning Spark (O'Reilly - Holden Karau, Andy Konwinski, Patrick Wendell & Matei Zaharia)\n",
    "\n",
    "### Spark Core üíñ\n",
    "\n",
    "Spark Core is the underlying general execution engine for the Spark platform that all other functionalities are built on top of.\n",
    "\n",
    "It provides many core functionalities such as task dispatching and scheduling, memory management and basic I/O (input/output) functionalities, exposed through an application programming interface.\n",
    "\n",
    "### Spark SQL üî¢\n",
    "\n",
    "Spark module for structured data processing.\n",
    "\n",
    "Spark SQL provides a programming abstraction called DataFrame and can also act as a distributed SQL query engine. DataFrames are the other main data format in Spark. Spark DataFrames are column oriented, they have a data schema which describes the name and type of all the available columns. It allows for easier processing but adds contraints on the cleanliness and structure of the data.\n",
    "\n",
    "Also they're called \"DataFrames\"\n",
    "\n",
    "At the core of Spark SQL is the Catalyst optimizer, which leverages advanced programming language features (such as Scala‚Äôs pattern matching and quasi quotes) to build an extensible query optimizer.\n",
    "\n",
    "<center><img src=\"https://full-stack-assets.s3.eu-west-3.amazonaws.com/images/Catalyst-Optimizer-diagram-152974c4-e1fc-4bb5-a788-c1ee71657ecd.png\"></center>\n",
    "\n",
    "\n",
    "Source: [https://databricks.com/glossary/catalyst-optimizer](https://databricks.com/glossary/catalyst-optimizer)\n",
    "\n",
    "### GraphX üìä\n",
    "\n",
    "Spark module for Graph computations.\n",
    "\n",
    "GraphX is a graph computation engine built on top of Spark that enables users to interactively build, transform and reason about graph structured data at scale. It comes with a library of common visualizations.\n",
    "\n",
    "### MLlib üîÆ\n",
    "\n",
    "Machine Learning library for Spark, inspired by Scikit-Learn (in particular, its pipelines system).\n",
    "\n",
    "Historically a RDD-based API, it now comes with a DataFrame-based API that has become the primary API while the RDD-based API is now in [maintenance mode](https://spark.apache.org/docs/latest/ml-guide.html#announcement-dataframe-based-api-is-primary-api).\n",
    "\n",
    "### Spark streaming üåä\n",
    "\n",
    "Spark module for stream processing.\n",
    "\n",
    "Streaming, also called Stream Processing is used to query continuous data stream and process this data within a small time period from the time of receiving the data. This is the opposite of batch processing, which occurs at a previously scheduled time independently from the data influx.\n",
    "\n",
    "Spark Streaming uses Spark Core's fast scheduling capability to perform streaming analytics. It ingests data in mini-batches and performs RDD transformations on those mini-batches of data. This design enables the same set of application code written for batch analytics to be used in streaming analytics, this comes at the cost of having to wait for the full mini-batch to be processed while alternatives like Apache Storm and Apache Flink process data by event and provide better speed.\n",
    "\n",
    "## Spark mechanics & [cluster-overview](https://spark.apache.org/docs/latest/cluster-overview.html) ‚öôÔ∏è‚öôÔ∏è\n",
    "\n",
    "> At a high level, every Spark application consists of a driver program that launches various parallel operations on a cluster. The driver program contains your application's main function and defines distributed datasets on the cluster, then applies operations on them.\n",
    "- Learning Spark, page 14\n",
    "\n",
    "<center><img src=\"https://full-stack-assets.s3.eu-west-3.amazonaws.com/images/cluster-overview-273ddf73-9063-47bb-9060-e094443700eb.png\" /></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [DAG](https://medium.com/@goyalsaurabh66/spark-basics-rdds-stages-tasks-and-dag-8da0f52f0454) (Directed Acyclic Graph) Scheduling üìÖ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In order to distribute the execution among the worker nodes, Spark transforms the logical execution plan into a physical execution plan (how the computation will actually take place). While doing so, it implements an execution plan that will maximize performances, in particular avoiding moving data across the network, because as we've seen, network latency is the worse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lazy Execution üò¥"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A consequence of Spark's being so efficient when computing operations is lazy execution. This concept sets Spark (and therefore PySpark, the python API for using the Spark framework in python language) from classic python.\n",
    "\n",
    "* meaning that an operation is not performed until an output is explicitly needed. For example, a join operation between two Spark dataframes will not immediately cause the join operation to be performed, which is how Pandas works. Instead, the join is performed once an output is added to the chain of operations to perform, such as displaying a sample of the resulting dataframe. One of the key differences between Pandas operations, where operations are eagerly performed and pulled into memory, is that PySpark operations are lazily performed and not pulled into memory until needed. One of the benefits of this approach is that the graph of operations to perform can be optimized before being sent to the cluster to execute.\n",
    "\n",
    "* Python runs in what we call **eager execution**, meaning everytime you write some code and execute it, the operations your code is asking the computer to execute happen immediatly and the result is returned.\n",
    "\n",
    "* In Spark things work a little differently, there are two types of operations: **transformations** and **actions**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformations üßô"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Transformations** are all operations that do not explicitely require the computer to return a result that should be stored, displayed or saved somewhere. These operations are only writen to the Graph waiting for an action to come up. For example, if you wish to calculate the frequency of all the the words in a set of text data, you may want to\n",
    "\n",
    "1. isolate each word,\n",
    "2. assign them a value of 1,\n",
    "3. group elements by key (meaning the word itself) so all occurences of the same words are grouped together,\n",
    "4. aggregate by summing the values associated with the words for each group.\n",
    "\n",
    "* None of these operations require direct display or storage of a result, they just constitute in a roadmap plan that can be optimized whenever you request to see the result!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actions ü¶∏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Actions** are operations that explicitely ask the computer to display or store the result of an operation. Taking our previous example, if we ask to see the complete list of words with their frequency, then all the previously mentionned transformation will actually execute one after the other. It can be very computing efficient because Spark knows all the operations that need to be done and can therefore plan accordingly, but additionnaly, if you're not looking to see the full result but just an extract to make sure the code runs correctly for example, then Spark will only work enough to give you want you want and stop (think of it as testing a piece of code on a sample instead of the full dataset for speed reasons).\n",
    "\n",
    "* Lazy execution makes Spark very computing efficient, but it also makes it harder to debug when something goes wrong. Because only some errors can be detected when running transformations because Spark does not actually try to run the code. You can later be met with a runtime error when using an action later (when the code actually starts running), and if the result you get is not the one you expected, you'll need to go back and inspect every transformation to find out where something went wrong.\n",
    "\n",
    "* Seems intimidating I know, but you can always set up actions like displaying the first few lines of data after each transformation in order to run sanity checks on what you are doing. It's a fair price to pay to be able to work with huge amounts of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixed language ‚òØÔ∏è‚òØÔ∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Apache Spark is written in `Scala`, making wide usage of the `Java Virtual Machine` and can be interfaced with: `Scala` (primary), `Java`, `Python` (`PySpark`) and `R`.\n",
    "\n",
    "* Because Spark is written in `Scala`, `PySpark`, the `Python` interface tends to follow Scala's principle, whether for small details like naming convention (PySpark's API is frequently not consistent with Python's standard good practices, for example using pascalCase instead of snake_case) or global programming paradigm like functional programming.\n",
    "\n",
    "* The functional paradigm is particularly adapted for distributed computing as it uses concept like immutability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PySpark üêç‚ú®"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* PySpark is the Python API for Apache Spark. Powerful, but some caveats:\n",
    "\n",
    "    - *Not as exhaustive as other's python libraries for data analysis and modeling (pandas, sklearn, etc..)*\n",
    "    - *Will be slower than these on small data*\n",
    "    - *Mixed language (harder to debug, common to find resources for Scala and not Python)*\n",
    "\n",
    "* Debugging PySpark is hard:\n",
    "\n",
    "    - *Debugging Distributed systems is hard*\n",
    "    - *Debugging mixed languages is hard*\n",
    "    - *Lazy evaluation can be difficult to debug*\n",
    "\n",
    "> üí° If you want an API closer to pandas while maintaining fast big data processing capabilities, take a look at [koalas](https://github.com/databricks/koalas) (still in beta) and [handyspark](https://towardsdatascience.com/handyspark-bringing-pandas-like-capabilities-to-spark-dataframes-5f1bcea9039e) (more robust).\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dd6t0uFzuR4X"
   },
   "source": [
    "# Install Spark (easy way : on Colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tt7ZS1_wGgjn",
    "outputId": "24385339-fd1f-43ec-a772-e8c0d882342a"
   },
   "outputs": [],
   "source": [
    "# !ls\n",
    "# As you see, we don't have yet spark installed ! \n",
    "!apt-get update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "kKhhwqK5reux"
   },
   "outputs": [],
   "source": [
    "# https://spark.apache.org/docs/latest/\n",
    "# Spark runs on Java 8/11, Scala 2.12, Python 3.6+ and R 3.5+. Java 8 prior to version 8u92 support is deprecated as of Spark 3.0.0.!\n",
    "# https://openjdk.java.net/\n",
    "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
    "# Q : What's the difference : openjdk-normal Vs. openjdk-headless ? \n",
    "# R : openjdk-normal permet de cr√©er des prog avec GUI. Ns n'avons pas besoin, ns allons lancer des calculs \n",
    "# https://stackoverflow.com/questions/24280872/difference-between-openjdk-6-jre-openjdk-6-jre-headless-openjdk-6-jre-lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EeX4zbr_rhVW",
    "outputId": "99783376-e1f0-4a75-ce6e-a854b7f4508b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-12-21 23:03:57--  https://archive.apache.org/dist/spark/spark-3.1.1/spark-3.1.1-bin-hadoop2.7.tgz\n",
      "Resolving archive.apache.org (archive.apache.org)... 138.201.131.134, 2a01:4f8:172:2ec5::2\n",
      "Connecting to archive.apache.org (archive.apache.org)|138.201.131.134|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 224374704 (214M) [application/x-gzip]\n",
      "Saving to: ‚Äòspark-3.1.1-bin-hadoop2.7.tgz‚Äô\n",
      "\n",
      "spark-3.1.1-bin-had 100%[===================>] 213.98M  26.1MB/s    in 9.0s    \n",
      "\n",
      "2021-12-21 23:04:07 (23.8 MB/s) - ‚Äòspark-3.1.1-bin-hadoop2.7.tgz‚Äô saved [224374704/224374704]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Le d√©p√¥t des archives : \n",
    "# https://archive.apache.org/dist/spark/\n",
    "\n",
    "!wget https://archive.apache.org/dist/spark/spark-3.1.1/spark-3.1.1-bin-hadoop2.7.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Ph-1W5aj8oPY"
   },
   "outputs": [],
   "source": [
    "# On d√©compresse\n",
    "!tar xf /content/spark-3.1.1-bin-hadoop2.7.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j3ypWOp0z2gU"
   },
   "outputs": [],
   "source": [
    "!wget -q http://archive.apache.org/dist/spark/spark-2.3.1/spark-2.3.1-bin-hadoop2.7.tgz\n",
    "# On d√©compresse\n",
    "!tar xf content/spark-2.3.1-bin-hadoop2.7.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GqmAfLIW0NtX",
    "outputId": "09037dbc-ca09-402a-db03-a4d1b7bd71e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark\n",
      "  Downloading pyspark-3.2.0.tar.gz (281.3 MB)\n",
      "\u001B[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 281.3 MB 42 kB/s \n",
      "\u001B[?25hCollecting py4j==0.10.9.2\n",
      "  Downloading py4j-0.10.9.2-py2.py3-none-any.whl (198 kB)\n",
      "\u001B[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 198 kB 43.8 MB/s \n",
      "\u001B[?25hBuilding wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for pyspark: filename=pyspark-3.2.0-py2.py3-none-any.whl size=281805912 sha256=8596828c3441a27474102dc28f6e7b97f6073f86f602d26ad89ee02f0c7a6651\n",
      "  Stored in directory: /root/.cache/pip/wheels/0b/de/d2/9be5d59d7331c6c2a7c1b6d1a4f463ce107332b1ecd4e80718\n",
      "Successfully built pyspark\n",
      "Installing collected packages: py4j, pyspark\n",
      "Successfully installed py4j-0.10.9.2 pyspark-3.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `findspark` pkg a pr obj : Find Spark Home, and initialize by adding `pyspark` to `sys.path`\n",
    "    ```\n",
    "    import findspark\n",
    "    findspark.init()\n",
    "    ```\n",
    "    <https://stackoverflow.com/questions/36799643/pyspark-sparkcontext-name-error-sc-in-jupyter>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ip7ZqBaW9pHl",
    "outputId": "17e3e534-c11c-47c6-de57-d45a45f421f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting findspark\n",
      "  Downloading findspark-1.4.2-py2.py3-none-any.whl (4.2 kB)\n",
      "Installing collected packages: findspark\n",
      "Successfully installed findspark-1.4.2\n"
     ]
    }
   ],
   "source": [
    "!pip install findspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FEuEkV0BlzAD"
   },
   "source": [
    "## Setup environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zoDuAqTJDTsT",
    "outputId": "1b57c933-cefb-4bcd-fdda-9269b186cb63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drive  sample_data  spark-3.1.1-bin-hadoop2.7  spark-3.1.1-bin-hadoop2.7.tgz\n"
     ]
    }
   ],
   "source": [
    "# We verify that spark is installed ! \n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "sdOOq4twHN1K"
   },
   "outputs": [],
   "source": [
    "# We add env var\n",
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop2.7\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 196
    },
    "id": "taiKyNYtCIHb",
    "outputId": "238bd63f-3837-4273-e5ba-475367455d6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark\n",
      "  Downloading pyspark-3.3.0.tar.gz (281.3 MB)\n",
      "\u001B[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 281.3 MB 44 kB/s  eta 0:00:01    |‚ñà‚ñà‚ñà‚ñç                            | 29.8 MB 2.3 MB/s eta 0:01:48     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                    | 106.1 MB 681 kB/s eta 0:04:17     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                   | 113.7 MB 2.7 MB/s eta 0:01:03     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                   | 114.3 MB 2.7 MB/s eta 0:01:03     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                | 135.5 MB 2.4 MB/s eta 0:01:02     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà              | 157.7 MB 530 kB/s eta 0:03:54     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà          | 193.6 MB 2.1 MB/s eta 0:00:42     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ       | 217.9 MB 2.7 MB/s eta 0:00:24     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 245.7 MB 2.9 MB/s eta 0:00:13     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 262.3 MB 2.7 MB/s eta 0:00:07     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 268.8 MB 2.7 MB/s eta 0:00:05\n",
      "\u001B[?25hCollecting py4j==0.10.9.5\n",
      "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
      "\u001B[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 199 kB 1.6 MB/s eta 0:00:01\n",
      "\u001B[?25hBuilding wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (setup.py) ... \u001B[?25ldone\n",
      "\u001B[?25h  Created wheel for pyspark: filename=pyspark-3.3.0-py2.py3-none-any.whl size=281764026 sha256=6aa57207242c1be9821c695bd018d23d50756dd25bc99472b01428220be92fde\n",
      "  Stored in directory: /home/sayf/.cache/pip/wheels/05/75/73/81f84d174299abca38dd6a06a5b98b08ae25fce50ab8986fa1\n",
      "Successfully built pyspark\n",
      "Installing collected packages: py4j, pyspark\n",
      "Successfully installed py4j-0.10.9.5 pyspark-3.3.0\n",
      "22/07/10 00:41:48 WARN Utils: Your hostname, DESKTOP-G4OOFUM resolves to a loopback address: 127.0.1.1; using 172.24.94.188 instead (on interface eth0)\n",
      "22/07/10 00:41:48 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/07/10 00:41:52 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/07/10 00:41:55 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://172.24.94.188:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f29803e8ee0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install pyspark\n",
    "# import findspark\n",
    "# findspark.init()\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "sc = SparkContext.getOrCreate()\n",
    "spark = SparkSession.builder.getOrCreate() \n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0RpslP0oOTYH",
    "outputId": "f04d0b2f-abed-401e-8a06-5695e540b0a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "from google.colab import files\n",
    "files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "7PKXvMNlOTYN",
    "outputId": "bdeb1b95-00bb-4f5a-8db0-352a5976a75c"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i5sW53PGOTYO",
    "outputId": "5779084e-8cf1-4e86-f14f-25cb4af32f79"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "os.listdir('/content/drive/MyDrive/data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Databricks Community](https://community.cloud.databricks.com/) üß±üß±"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What you will learn in this course üßêüßê\n",
    "* This course is a demo that will introduce to you one of the main data formats in spark which is spark RDDs (Resilient Distributed Datasets), we will walk you through how to use this low level data format using pyspark.\n",
    "Here's the outline:\n",
    "\n",
    "* Databricks\n",
    "    * Login Page\n",
    "    * Homepage\n",
    "    * Workspace\n",
    "    * Create Folder\n",
    "    * Upload Notebook\n",
    "    * Notebook View"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fRKvyxRHWtmU"
   },
   "source": [
    "* Databricks is a cloud service provider which makes available clusters of machines with the spark framework already installed on them. Spark can be a real pain to set up, but gets amazing results once it's all up and running. We'll use databricks here so we can all work on a standardized environment!\n",
    "\n",
    "* We'll use the community edition which is free, but limits the number and performance of the machines in our cluster. However this is not going to change a thing in terms of the code we'll right, whatever we'll learn here can scale up by connecting to a bigger cluster.\n",
    "\n",
    "* Here's a walkthrough of what you should do once you are logged in ;)\n",
    "\n",
    "### Login Page üîë\n",
    "![](https://full-stack-assets.s3.eu-west-3.amazonaws.com/images/Databricks/databricks_login.PNG)\n",
    "\n",
    "### Homepage üè†\n",
    "![](https://full-stack-assets.s3.eu-west-3.amazonaws.com/images/Databricks/databricks_homepage.PNG)\n",
    "\n",
    "### Workspace üë∑\n",
    "![](https://full-stack-assets.s3.eu-west-3.amazonaws.com/images/Databricks/databricks_workspace.PNG)\n",
    "\n",
    "### Create Folder üìÅ\n",
    "![](https://full-stack-assets.s3.eu-west-3.amazonaws.com/images/Databricks/databricks_create_folder.PNG)\n",
    "\n",
    "### Upload Notebook üì§\n",
    "![](https://full-stack-assets.s3.eu-west-3.amazonaws.com/images/Databricks/databricks_import_notebook.PNG)\n",
    "\n",
    "### Notebook View üìù\n",
    "![](https://full-stack-assets.s3.eu-west-3.amazonaws.com/images/Databricks/databricks_notebook_view.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b2PbELbPbjVV"
   },
   "source": [
    "# Install Spark (en local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "# import findspark\n",
    "# findspark.init(spark_home='/home/sayf/hadoop/spark')\n",
    "# findspark.init(spark_home=r'C:/Users/bejao/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chargement de Spark : [SparkSession](https://sparkbyexamples.com/pyspark/pyspark-what-is-sparksession/) & [SparkContext](https://sparkbyexamples.com/spark/how-to-create-a-sparksession-and-spark-context/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/01 14:50:18 WARN Utils: Your hostname, DESKTOP-G4OOFUM resolves to a loopback address: 127.0.1.1; using 172.29.192.131 instead (on interface eth0)\n",
      "22/09/01 14:50:18 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/01 14:50:23 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://172.29.192.131:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>spark</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f02641223d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "# spark = SparkSession.builder.getOrCreate()\n",
    "# local[*] => On utilise les coeurs de la marchine\n",
    "spark = SparkSession.builder.master(\"local[*]\") \\\n",
    "                    .appName('spark') \\\n",
    "                    .getOrCreate()\n",
    "# spark.conf.set('spark.sql.repl.eagerEval.enabled', True)\n",
    "sc = spark.sparkContext.setLogLevel('OFF')\n",
    "# from pyspark.sql.types import IntegerType, StringType, DoubleType, BooleanType, TimestampType, StructField, StructType\n",
    "# import pyspark.sql.functions as F  \n",
    "\n",
    "path = 'file:///databricks/driver/Crimes-2001_to_present.txt'\n",
    "path = 'file:///mnt/c/Users/bejao/OneDrive/data/Crimes-2001_to_present.txt'\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://172.23.154.28:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fdb54a1f220>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SparkSession.getActiveSession()\n",
    "# spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "9b2a405a-ccc1-4de3-a2e8-8f508d5b606e",
     "showTitle": false,
     "title": ""
    },
    "id": "Ok464KgqfgYx"
   },
   "source": [
    "# PySpark - Dataframes üóÑÔ∏èüóÑÔ∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What will you learn in this course? üßêüßê\n",
    "\n",
    "* Running SQL queries against DataFrames\n",
    "    * Select columns in Spark DataFrames\n",
    "    * Actions\n",
    "        * `.show()`\n",
    "        * `.printSchema()`\n",
    "        * `.take()`\n",
    "        * `.collect()`\n",
    "        * `.count()`\n",
    "        * `.describe()`\n",
    "        * `display()`\n",
    "        * `.toPandas()`\n",
    "        * `..write()`\n",
    "    * Transformations\n",
    "        * `.na`\n",
    "        * `.fill()`\n",
    "        * `.drop()`\n",
    "        * `.isNull()`\n",
    "        * `.replace()`\n",
    "        * `.sql()`\n",
    "        * `.select()`\n",
    "        * `.alias(...)`\n",
    "        * `.drop(...)`\n",
    "        * `.limit()`\n",
    "        * `.filter()`\n",
    "        * `.selectExpr()`\n",
    "        * `.dropDuplicates()`\n",
    "        * `.distinct()`\n",
    "        * `.orderBy()`\n",
    "        * `.groupBy()`\n",
    "        * `.withColumn()`\n",
    "        * `.withColumnRenamed()`\n",
    "        * Chaining everything together\n",
    "        \n",
    "* Some differences with pandas' DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ysUlfFrN5OD"
   },
   "source": [
    "# Download and [preprocessing](https://spark.apache.org/docs/latest/api/python/getting_started/quickstart_df.html#Viewing-Data) [Chicago's Reported Crime Data](https://data.cityofchicago.org/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FDtw5Hy3N-pV",
    "outputId": "8f750026-b71a-4c9a-a7f9-97bfb9bb36be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-12-21 23:07:41--  https://data.cityofchicago.org/api/views/ijzp-q8t2/rows.csv?accessType=DOWNLOAD\n",
      "Resolving data.cityofchicago.org (data.cityofchicago.org)... 52.206.68.26, 52.206.140.205, 52.206.140.199\n",
      "Connecting to data.cityofchicago.org (data.cityofchicago.org)|52.206.68.26|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [text/csv]\n",
      "Saving to: ‚Äòrows.csv?accessType=DOWNLOAD‚Äô\n",
      "\n",
      "rows.csv?accessType     [      <=>           ]   1.64G  3.39MB/s    in 8m 53s  \n",
      "\n",
      "2021-12-21 23:16:35 (3.15 MB/s) - ‚Äòrows.csv?accessType=DOWNLOAD‚Äô saved [1760142265]\n",
      "\n",
      "drive\t\t     sample_data\t\tspark-3.1.1-bin-hadoop2.7.tgz\n",
      "reported-crimes.csv  spark-3.1.1-bin-hadoop2.7\n"
     ]
    }
   ],
   "source": [
    "# Download the file\n",
    "!wget https://data.cityofchicago.org/api/views/ijzp-q8t2/rows.csv?accessType=DOWNLOAD\n",
    "# Rename the file \n",
    "!mv rows.csv?accessType=DOWNLOAD reported-crimes.csv\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read a huge csv : [doc offic](https://spark.apache.org/docs/latest/sql-data-sources-csv.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture avec Python : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Case Number</th>\n",
       "      <th>Date</th>\n",
       "      <th>Block</th>\n",
       "      <th>IUCR</th>\n",
       "      <th>Primary Type</th>\n",
       "      <th>Description</th>\n",
       "      <th>Location Description</th>\n",
       "      <th>Arrest</th>\n",
       "      <th>Domestic</th>\n",
       "      <th>...</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Location</th>\n",
       "      <th>Historical Wards 2003-2015</th>\n",
       "      <th>Zip Codes</th>\n",
       "      <th>Community Areas</th>\n",
       "      <th>Census Tracts</th>\n",
       "      <th>Wards</th>\n",
       "      <th>Boundaries - ZIP Codes</th>\n",
       "      <th>Police Districts</th>\n",
       "      <th>Police Beats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11727746</td>\n",
       "      <td>JC312349</td>\n",
       "      <td>06/18/2019 11:55:00 PM</td>\n",
       "      <td>0000X W 79TH ST</td>\n",
       "      <td>0484</td>\n",
       "      <td>BATTERY</td>\n",
       "      <td>PRO EMP HANDS NO/MIN INJURY</td>\n",
       "      <td>CTA STATION</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11728171</td>\n",
       "      <td>JC312895</td>\n",
       "      <td>06/18/2019 11:55:00 PM</td>\n",
       "      <td>044XX S CHRISTIANA AVE</td>\n",
       "      <td>1320</td>\n",
       "      <td>CRIMINAL DAMAGE</td>\n",
       "      <td>TO VEHICLE</td>\n",
       "      <td>STREET</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11728165</td>\n",
       "      <td>JC312901</td>\n",
       "      <td>06/18/2019 11:55:00 PM</td>\n",
       "      <td>044XX S CHRISTIANA AVE</td>\n",
       "      <td>1320</td>\n",
       "      <td>CRIMINAL DAMAGE</td>\n",
       "      <td>TO VEHICLE</td>\n",
       "      <td>STREET</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11727579</td>\n",
       "      <td>JC312360</td>\n",
       "      <td>06/18/2019 11:50:00 PM</td>\n",
       "      <td>076XX S COTTAGE GROVE AVE</td>\n",
       "      <td>0470</td>\n",
       "      <td>PUBLIC PEACE VIOLATION</td>\n",
       "      <td>RECKLESS CONDUCT</td>\n",
       "      <td>STREET</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11727572</td>\n",
       "      <td>JC312333</td>\n",
       "      <td>06/18/2019 11:50:00 PM</td>\n",
       "      <td>040XX W SCHOOL ST</td>\n",
       "      <td>0460</td>\n",
       "      <td>BATTERY</td>\n",
       "      <td>SIMPLE</td>\n",
       "      <td>BAR OR TAVERN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6899945</th>\n",
       "      <td>1403263</td>\n",
       "      <td>G117094</td>\n",
       "      <td>01/01/2001 12:00:00 AM</td>\n",
       "      <td>084XX S PRAIRIE AV</td>\n",
       "      <td>1120</td>\n",
       "      <td>DECEPTIVE PRACTICE</td>\n",
       "      <td>FORGERY</td>\n",
       "      <td>BANK</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>-87.617741</td>\n",
       "      <td>(41.741163326, -87.617740827)</td>\n",
       "      <td>31.0</td>\n",
       "      <td>21546.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>241.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6899946</th>\n",
       "      <td>1352564</td>\n",
       "      <td>G055473</td>\n",
       "      <td>01/01/2001 12:00:00 AM</td>\n",
       "      <td>018XX N TALMAN AV</td>\n",
       "      <td>0820</td>\n",
       "      <td>THEFT</td>\n",
       "      <td>$500 AND UNDER</td>\n",
       "      <td>STREET</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>-87.693605</td>\n",
       "      <td>(41.914955409, -87.693605188)</td>\n",
       "      <td>24.0</td>\n",
       "      <td>22535.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>171.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6899947</th>\n",
       "      <td>1313893</td>\n",
       "      <td>G000035</td>\n",
       "      <td>01/01/2001 12:00:00 AM</td>\n",
       "      <td>027XX W NELSON ST</td>\n",
       "      <td>1310</td>\n",
       "      <td>CRIMINAL DAMAGE</td>\n",
       "      <td>TO PROPERTY</td>\n",
       "      <td>RESIDENCE</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>-87.697098</td>\n",
       "      <td>(41.936549915, -87.697097823)</td>\n",
       "      <td>24.0</td>\n",
       "      <td>21538.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>467.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>174.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6899948</th>\n",
       "      <td>1374123</td>\n",
       "      <td>G083329</td>\n",
       "      <td>01/01/2001 12:00:00 AM</td>\n",
       "      <td>045XX S LAPORTE AV</td>\n",
       "      <td>0820</td>\n",
       "      <td>THEFT</td>\n",
       "      <td>$500 AND UNDER</td>\n",
       "      <td>STREET</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>-87.747061</td>\n",
       "      <td>(41.810679064, -87.747061323)</td>\n",
       "      <td>35.0</td>\n",
       "      <td>22268.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>604.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>112.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6899949</th>\n",
       "      <td>1329588</td>\n",
       "      <td>G025242</td>\n",
       "      <td>01/01/2001 12:00:00 AM</td>\n",
       "      <td>061XX S COTTAGE GROVE AV</td>\n",
       "      <td>0820</td>\n",
       "      <td>THEFT</td>\n",
       "      <td>$500 AND UNDER</td>\n",
       "      <td>STREET</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>-87.606155</td>\n",
       "      <td>(41.783961993, -87.606155349)</td>\n",
       "      <td>53.0</td>\n",
       "      <td>22260.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>471.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>275.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6899950 rows √ó 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID Case Number                    Date  \\\n",
       "0        11727746    JC312349  06/18/2019 11:55:00 PM   \n",
       "1        11728171    JC312895  06/18/2019 11:55:00 PM   \n",
       "2        11728165    JC312901  06/18/2019 11:55:00 PM   \n",
       "3        11727579    JC312360  06/18/2019 11:50:00 PM   \n",
       "4        11727572    JC312333  06/18/2019 11:50:00 PM   \n",
       "...           ...         ...                     ...   \n",
       "6899945   1403263     G117094  01/01/2001 12:00:00 AM   \n",
       "6899946   1352564     G055473  01/01/2001 12:00:00 AM   \n",
       "6899947   1313893     G000035  01/01/2001 12:00:00 AM   \n",
       "6899948   1374123     G083329  01/01/2001 12:00:00 AM   \n",
       "6899949   1329588     G025242  01/01/2001 12:00:00 AM   \n",
       "\n",
       "                             Block  IUCR            Primary Type  \\\n",
       "0                  0000X W 79TH ST  0484                 BATTERY   \n",
       "1           044XX S CHRISTIANA AVE  1320         CRIMINAL DAMAGE   \n",
       "2           044XX S CHRISTIANA AVE  1320         CRIMINAL DAMAGE   \n",
       "3        076XX S COTTAGE GROVE AVE  0470  PUBLIC PEACE VIOLATION   \n",
       "4                040XX W SCHOOL ST  0460                 BATTERY   \n",
       "...                            ...   ...                     ...   \n",
       "6899945         084XX S PRAIRIE AV  1120      DECEPTIVE PRACTICE   \n",
       "6899946          018XX N TALMAN AV  0820                   THEFT   \n",
       "6899947          027XX W NELSON ST  1310         CRIMINAL DAMAGE   \n",
       "6899948         045XX S LAPORTE AV  0820                   THEFT   \n",
       "6899949   061XX S COTTAGE GROVE AV  0820                   THEFT   \n",
       "\n",
       "                         Description Location Description  Arrest  Domestic  \\\n",
       "0        PRO EMP HANDS NO/MIN INJURY          CTA STATION   False     False   \n",
       "1                         TO VEHICLE               STREET   False     False   \n",
       "2                         TO VEHICLE               STREET   False     False   \n",
       "3                   RECKLESS CONDUCT               STREET    True     False   \n",
       "4                             SIMPLE        BAR OR TAVERN   False     False   \n",
       "...                              ...                  ...     ...       ...   \n",
       "6899945                      FORGERY                 BANK   False     False   \n",
       "6899946               $500 AND UNDER               STREET   False     False   \n",
       "6899947                  TO PROPERTY            RESIDENCE   False     False   \n",
       "6899948               $500 AND UNDER               STREET   False     False   \n",
       "6899949               $500 AND UNDER               STREET   False     False   \n",
       "\n",
       "         ...  Longitude                       Location  \\\n",
       "0        ...        NaN                            NaN   \n",
       "1        ...        NaN                            NaN   \n",
       "2        ...        NaN                            NaN   \n",
       "3        ...        NaN                            NaN   \n",
       "4        ...        NaN                            NaN   \n",
       "...      ...        ...                            ...   \n",
       "6899945  ... -87.617741  (41.741163326, -87.617740827)   \n",
       "6899946  ... -87.693605  (41.914955409, -87.693605188)   \n",
       "6899947  ... -87.697098  (41.936549915, -87.697097823)   \n",
       "6899948  ... -87.747061  (41.810679064, -87.747061323)   \n",
       "6899949  ... -87.606155  (41.783961993, -87.606155349)   \n",
       "\n",
       "         Historical Wards 2003-2015  Zip Codes Community Areas  Census Tracts  \\\n",
       "0                               NaN        NaN             NaN            NaN   \n",
       "1                               NaN        NaN             NaN            NaN   \n",
       "2                               NaN        NaN             NaN            NaN   \n",
       "3                               NaN        NaN             NaN            NaN   \n",
       "4                               NaN        NaN             NaN            NaN   \n",
       "...                             ...        ...             ...            ...   \n",
       "6899945                        31.0    21546.0            40.0          406.0   \n",
       "6899946                        24.0    22535.0            23.0          180.0   \n",
       "6899947                        24.0    21538.0            22.0          467.0   \n",
       "6899948                        35.0    22268.0            53.0          604.0   \n",
       "6899949                        53.0    22260.0             9.0          471.0   \n",
       "\n",
       "         Wards  Boundaries - ZIP Codes Police Districts  Police Beats  \n",
       "0          NaN                     NaN              NaN           NaN  \n",
       "1          NaN                     NaN              NaN           NaN  \n",
       "2          NaN                     NaN              NaN           NaN  \n",
       "3          NaN                     NaN              NaN           NaN  \n",
       "4          NaN                     NaN              NaN           NaN  \n",
       "...        ...                     ...              ...           ...  \n",
       "6899945   32.0                    61.0             20.0         241.0  \n",
       "6899946   41.0                     1.0              7.0         171.0  \n",
       "6899947   20.0                    39.0              7.0         174.0  \n",
       "6899948   28.0                     7.0             13.0         112.0  \n",
       "6899949    4.0                    60.0             18.0         275.0  \n",
       "\n",
       "[6899950 rows x 30 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv(path)\n",
    "# Le lecture est tr√®s co√ªteuse en temps et en m√©moire. Il faut passer par un outil d√©di√© √† la Big Data => Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture avec Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[read.csv](https://spark.apache.org/docs/2.2.0/api/python/pyspark.sql.html#pyspark.sql.DataFrameReader.csv), [read.json](https://spark.apache.org/docs/2.2.0/api/python/pyspark.sql.html#pyspark.sql.DataFrameReader.json), [read.parquet](https://spark.apache.org/docs/2.2.0/api/python/pyspark.sql.html#pyspark.sql.DataFrameReader.parquet), option [InferSchema](https://www.learntospark.com/2020/10/spark-optimization-technique-inferschema.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type\n",
       "int        16\n",
       "string     10\n",
       "boolean     2\n",
       "double      2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lecture rapide (sans sp√©cifier les options n√©cessaires)\n",
    "# df = spark.read.csv(path)\n",
    "\n",
    "# Lecture avec l'option 'header=True' (pour rajouter les noms de colonnes √† votre df)\n",
    "# df = spark.read.csv(path, header=True)\n",
    "# df.rdd.getNumPartitions()\n",
    "\n",
    "# Lecture avec l'option 'inferSchema' (plus co√ªteuse : 30s). Elle permet de transformer les colonnes en types plus pr√©cis : int  / boolean / string / double...\n",
    "# bien s√ªr spark trouve les types uniquement si le fichier d'origine permet de les trouver de mani√®re simple\n",
    "\n",
    "df = spark.read.csv(path, header=True, inferSchema=True)\n",
    "\n",
    "df = spark.read.format(\"csv\").option(\"header\",\"true\")\\\n",
    "                             .option(\"delimiter\", \",\")\\\n",
    "                             .load(path)\n",
    "\n",
    "# Lire √† partir de l'API ? \n",
    "url = 'https://data.cityofchicago.org/resource/ijzp-q8t2.json'\n",
    "resp = requests.get(url=url).json()\n",
    "df = spark.createDataFrame(resp)\n",
    "\n",
    "# Boucker sur ttes les ann√©es et concatener les dfs\n",
    "import requests\n",
    "import json\n",
    "year=2001\n",
    "data = {}\n",
    "while year <= 2022:\n",
    "    print(year)\n",
    "    r = requests.get(f'https://data.cityofchicago.org/resource/ijzp-q8t2.json?$limit=9223372036854775807&$where=year={year}').json()\n",
    "    data[year]= spark.createDataFrame(r)\n",
    "    year +=1\n",
    "data\n",
    "\n",
    "df_concat = data.get(2001).union(data.get(2002)).union(data.get(2003))\n",
    "df_concat\n",
    "\n",
    "from functools import reduce\n",
    "from pyspark.sql import DataFrame\n",
    "year = range(2001,2023)\n",
    "dfs = []\n",
    "for y in year:\n",
    "    dfs.append(data.get(y))\n",
    "dfs\n",
    "# dfs = [data.get(2001), data.get(2002)]\n",
    "df_ = reduce(DataFrame.union, dfs)\n",
    "\n",
    "\n",
    "## Lire un fichier Excel  \n",
    "df = spark.read.format(\"com.crealytics.spark.excel\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load(\"/FileStore/tables/new_ville.xlsx\") \\\n",
    "df.show()\n",
    "\n",
    "# df #  Affichage intelligent, uniquement les cols et leur type, contexte Big Data (pas le df en entier )\n",
    "# df.show(5)\n",
    "df.show(1, vertical=True)\n",
    "# https://sqlrelease.com/show-full-column-content-in-spark\n",
    "# df.show(1, vertical=True, truncate=False)\n",
    "\n",
    "\n",
    "df.dtypes\n",
    "# type(df.dtypes)\n",
    "pd.DataFrame(df.dtypes, columns=['col', 'type']).value_counts('type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Affichage comme dans un notebook natif](https://spark.apache.org/docs/latest/api/python/getting_started/quickstart_df.html#Viewing-Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/01/07 20:29:16 WARN util.package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>ID</th><th>Case Number</th><th>Date</th><th>Block</th><th>IUCR</th><th>Primary Type</th><th>Description</th><th>Location Description</th><th>Arrest</th><th>Domestic</th><th>Beat</th><th>District</th><th>Ward</th><th>Community Area</th><th>FBI Code</th><th>X Coordinate</th><th>Y Coordinate</th><th>Year</th><th>Updated On</th><th>Latitude</th><th>Longitude</th><th>Location</th><th>Historical Wards 2003-2015</th><th>Zip Codes</th><th>Community Areas</th><th>Census Tracts</th><th>Wards</th><th>Boundaries - ZIP Codes</th><th>Police Districts</th><th>Police Beats</th></tr>\n",
       "<tr><td>11727746</td><td>JC312349</td><td>06/18/2019 11:55:...</td><td>0000X W 79TH ST</td><td>0484</td><td>BATTERY</td><td>PRO EMP HANDS NO/...</td><td>CTA STATION</td><td>false</td><td>false</td><td>0623</td><td>006</td><td>6</td><td>44</td><td>08B</td><td>null</td><td>null</td><td>2019</td><td>06/25/2019 04:19:...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr>\n",
       "<tr><td>11728171</td><td>JC312895</td><td>06/18/2019 11:55:...</td><td>044XX S CHRISTIAN...</td><td>1320</td><td>CRIMINAL DAMAGE</td><td>TO VEHICLE</td><td>STREET</td><td>false</td><td>false</td><td>0821</td><td>008</td><td>14</td><td>58</td><td>14</td><td>null</td><td>null</td><td>2019</td><td>06/25/2019 04:19:...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr>\n",
       "<tr><td>11728165</td><td>JC312901</td><td>06/18/2019 11:55:...</td><td>044XX S CHRISTIAN...</td><td>1320</td><td>CRIMINAL DAMAGE</td><td>TO VEHICLE</td><td>STREET</td><td>false</td><td>false</td><td>0821</td><td>008</td><td>14</td><td>58</td><td>14</td><td>null</td><td>null</td><td>2019</td><td>06/25/2019 04:19:...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr>\n",
       "<tr><td>11727579</td><td>JC312360</td><td>06/18/2019 11:50:...</td><td>076XX S COTTAGE G...</td><td>0470</td><td>PUBLIC PEACE VIOL...</td><td>RECKLESS CONDUCT</td><td>STREET</td><td>true</td><td>false</td><td>0624</td><td>006</td><td>6</td><td>69</td><td>24</td><td>null</td><td>null</td><td>2019</td><td>06/25/2019 04:19:...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr>\n",
       "<tr><td>11727572</td><td>JC312333</td><td>06/18/2019 11:50:...</td><td>040XX W SCHOOL ST</td><td>0460</td><td>BATTERY</td><td>SIMPLE</td><td>BAR OR TAVERN</td><td>false</td><td>false</td><td>1731</td><td>017</td><td>30</td><td>16</td><td>08B</td><td>null</td><td>null</td><td>2019</td><td>06/25/2019 04:19:...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr>\n",
       "<tr><td>11727655</td><td>JC312367</td><td>06/18/2019 11:45:...</td><td>116XX S PEORIA ST</td><td>031A</td><td>ROBBERY</td><td>ARMED: HANDGUN</td><td>STREET</td><td>false</td><td>false</td><td>0524</td><td>005</td><td>34</td><td>53</td><td>03</td><td>null</td><td>null</td><td>2019</td><td>06/25/2019 04:19:...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr>\n",
       "<tr><td>11727595</td><td>JC312338</td><td>06/18/2019 11:45:...</td><td>067XX N SHERIDAN RD</td><td>0910</td><td>MOTOR VEHICLE THEFT</td><td>AUTOMOBILE</td><td>STREET</td><td>false</td><td>false</td><td>2432</td><td>024</td><td>49</td><td>1</td><td>07</td><td>null</td><td>null</td><td>2019</td><td>06/25/2019 04:19:...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr>\n",
       "<tr><td>11727611</td><td>JC312327</td><td>06/18/2019 11:39:...</td><td>002XX E 121ST PL</td><td>1320</td><td>CRIMINAL DAMAGE</td><td>TO VEHICLE</td><td>STREET</td><td>false</td><td>false</td><td>0532</td><td>005</td><td>9</td><td>53</td><td>14</td><td>null</td><td>null</td><td>2019</td><td>06/25/2019 04:19:...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr>\n",
       "<tr><td>11727571</td><td>JC312317</td><td>06/18/2019 11:32:...</td><td>059XX S PAULINA ST</td><td>051A</td><td>ASSAULT</td><td>AGGRAVATED: HANDGUN</td><td>RESIDENCE PORCH/H...</td><td>false</td><td>false</td><td>0714</td><td>007</td><td>15</td><td>67</td><td>04A</td><td>null</td><td>null</td><td>2019</td><td>06/25/2019 04:19:...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr>\n",
       "<tr><td>11727883</td><td>JC312602</td><td>06/18/2019 11:30:...</td><td>025XX S TRUMBULL AVE</td><td>0810</td><td>THEFT</td><td>OVER $500</td><td>STREET</td><td>false</td><td>false</td><td>1024</td><td>010</td><td>22</td><td>30</td><td>06</td><td>null</td><td>null</td><td>2019</td><td>06/25/2019 04:19:...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr>\n",
       "<tr><td>11727593</td><td>JC312328</td><td>06/18/2019 11:30:...</td><td>084XX S SAGINAW AVE</td><td>0486</td><td>BATTERY</td><td>DOMESTIC BATTERY ...</td><td>RESIDENCE</td><td>false</td><td>true</td><td>0423</td><td>004</td><td>7</td><td>46</td><td>08B</td><td>null</td><td>null</td><td>2019</td><td>06/25/2019 04:19:...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr>\n",
       "<tr><td>11727545</td><td>JC312319</td><td>06/18/2019 11:20:...</td><td>021XX W 35TH ST</td><td>2022</td><td>NARCOTICS</td><td>POSS: COCAINE</td><td>STREET</td><td>true</td><td>false</td><td>0912</td><td>009</td><td>12</td><td>59</td><td>18</td><td>null</td><td>null</td><td>2019</td><td>06/25/2019 04:19:...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr>\n",
       "<tr><td>11727554</td><td>JC312308</td><td>06/18/2019 11:20:...</td><td>013XX S KILDARE AVE</td><td>051A</td><td>ASSAULT</td><td>AGGRAVATED: HANDGUN</td><td>APARTMENT</td><td>false</td><td>false</td><td>1011</td><td>010</td><td>24</td><td>29</td><td>04A</td><td>null</td><td>null</td><td>2019</td><td>06/25/2019 04:19:...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr>\n",
       "<tr><td>11727632</td><td>JC312316</td><td>06/18/2019 11:15:...</td><td>085XX S PARNELL AVE</td><td>0486</td><td>BATTERY</td><td>DOMESTIC BATTERY ...</td><td>APARTMENT</td><td>false</td><td>true</td><td>0622</td><td>006</td><td>21</td><td>71</td><td>08B</td><td>null</td><td>null</td><td>2019</td><td>06/25/2019 04:19:...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr>\n",
       "<tr><td>11727619</td><td>JC312309</td><td>06/18/2019 11:15:...</td><td>011XX S MICHIGAN AVE</td><td>0460</td><td>BATTERY</td><td>SIMPLE</td><td>SIDEWALK</td><td>false</td><td>false</td><td>0123</td><td>001</td><td>4</td><td>32</td><td>08B</td><td>null</td><td>null</td><td>2019</td><td>06/25/2019 04:19:...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr>\n",
       "<tr><td>11727688</td><td>JC312325</td><td>06/18/2019 11:15:...</td><td>050XX W MADISON ST</td><td>0460</td><td>BATTERY</td><td>SIMPLE</td><td>SIDEWALK</td><td>false</td><td>false</td><td>1533</td><td>015</td><td>28</td><td>25</td><td>08B</td><td>null</td><td>null</td><td>2019</td><td>06/25/2019 04:19:...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr>\n",
       "<tr><td>11727538</td><td>JC312293</td><td>06/18/2019 11:08:...</td><td>015XX S HOMAN AVE</td><td>0486</td><td>BATTERY</td><td>DOMESTIC BATTERY ...</td><td>APARTMENT</td><td>true</td><td>true</td><td>1021</td><td>010</td><td>24</td><td>29</td><td>08B</td><td>null</td><td>null</td><td>2019</td><td>06/25/2019 04:19:...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr>\n",
       "<tr><td>11727609</td><td>JC312341</td><td>06/18/2019 11:08:...</td><td>080XX S STONY ISL...</td><td>4650</td><td>OTHER OFFENSE</td><td>SEX OFFENDER: FAI...</td><td>STREET</td><td>false</td><td>false</td><td>0411</td><td>004</td><td>8</td><td>45</td><td>26</td><td>null</td><td>null</td><td>2019</td><td>06/25/2019 04:19:...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr>\n",
       "<tr><td>11727628</td><td>JC312306</td><td>06/18/2019 11:00:...</td><td>003XX W CHICAGO AVE</td><td>0460</td><td>BATTERY</td><td>SIMPLE</td><td>CTA TRAIN</td><td>false</td><td>false</td><td>1823</td><td>018</td><td>27</td><td>8</td><td>08B</td><td>null</td><td>null</td><td>2019</td><td>06/25/2019 04:19:...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr>\n",
       "<tr><td>11729739</td><td>JC314541</td><td>06/18/2019 11:00:...</td><td>079XX S WOODLAWN AVE</td><td>0330</td><td>ROBBERY</td><td>AGGRAVATED</td><td>ALLEY</td><td>false</td><td>false</td><td>0411</td><td>004</td><td>8</td><td>45</td><td>03</td><td>null</td><td>null</td><td>2019</td><td>06/25/2019 04:19:...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "+--------+-----------+--------------------+--------------------+----+--------------------+--------------------+--------------------+------+--------+----+--------+----+--------------+--------+------------+------------+----+--------------------+--------+---------+--------+--------------------------+---------+---------------+-------------+-----+----------------------+----------------+------------+\n",
       "|      ID|Case Number|                Date|               Block|IUCR|        Primary Type|         Description|Location Description|Arrest|Domestic|Beat|District|Ward|Community Area|FBI Code|X Coordinate|Y Coordinate|Year|          Updated On|Latitude|Longitude|Location|Historical Wards 2003-2015|Zip Codes|Community Areas|Census Tracts|Wards|Boundaries - ZIP Codes|Police Districts|Police Beats|\n",
       "+--------+-----------+--------------------+--------------------+----+--------------------+--------------------+--------------------+------+--------+----+--------+----+--------------+--------+------------+------------+----+--------------------+--------+---------+--------+--------------------------+---------+---------------+-------------+-----+----------------------+----------------+------------+\n",
       "|11727746|   JC312349|06/18/2019 11:55:...|     0000X W 79TH ST|0484|             BATTERY|PRO EMP HANDS NO/...|         CTA STATION| false|   false|0623|     006|   6|            44|     08B|        null|        null|2019|06/25/2019 04:19:...|    null|     null|    null|                      null|     null|           null|         null| null|                  null|            null|        null|\n",
       "|11728171|   JC312895|06/18/2019 11:55:...|044XX S CHRISTIAN...|1320|     CRIMINAL DAMAGE|          TO VEHICLE|              STREET| false|   false|0821|     008|  14|            58|      14|        null|        null|2019|06/25/2019 04:19:...|    null|     null|    null|                      null|     null|           null|         null| null|                  null|            null|        null|\n",
       "|11728165|   JC312901|06/18/2019 11:55:...|044XX S CHRISTIAN...|1320|     CRIMINAL DAMAGE|          TO VEHICLE|              STREET| false|   false|0821|     008|  14|            58|      14|        null|        null|2019|06/25/2019 04:19:...|    null|     null|    null|                      null|     null|           null|         null| null|                  null|            null|        null|\n",
       "|11727579|   JC312360|06/18/2019 11:50:...|076XX S COTTAGE G...|0470|PUBLIC PEACE VIOL...|    RECKLESS CONDUCT|              STREET|  true|   false|0624|     006|   6|            69|      24|        null|        null|2019|06/25/2019 04:19:...|    null|     null|    null|                      null|     null|           null|         null| null|                  null|            null|        null|\n",
       "|11727572|   JC312333|06/18/2019 11:50:...|   040XX W SCHOOL ST|0460|             BATTERY|              SIMPLE|       BAR OR TAVERN| false|   false|1731|     017|  30|            16|     08B|        null|        null|2019|06/25/2019 04:19:...|    null|     null|    null|                      null|     null|           null|         null| null|                  null|            null|        null|\n",
       "|11727655|   JC312367|06/18/2019 11:45:...|   116XX S PEORIA ST|031A|             ROBBERY|      ARMED: HANDGUN|              STREET| false|   false|0524|     005|  34|            53|      03|        null|        null|2019|06/25/2019 04:19:...|    null|     null|    null|                      null|     null|           null|         null| null|                  null|            null|        null|\n",
       "|11727595|   JC312338|06/18/2019 11:45:...| 067XX N SHERIDAN RD|0910| MOTOR VEHICLE THEFT|          AUTOMOBILE|              STREET| false|   false|2432|     024|  49|             1|      07|        null|        null|2019|06/25/2019 04:19:...|    null|     null|    null|                      null|     null|           null|         null| null|                  null|            null|        null|\n",
       "|11727611|   JC312327|06/18/2019 11:39:...|    002XX E 121ST PL|1320|     CRIMINAL DAMAGE|          TO VEHICLE|              STREET| false|   false|0532|     005|   9|            53|      14|        null|        null|2019|06/25/2019 04:19:...|    null|     null|    null|                      null|     null|           null|         null| null|                  null|            null|        null|\n",
       "|11727571|   JC312317|06/18/2019 11:32:...|  059XX S PAULINA ST|051A|             ASSAULT| AGGRAVATED: HANDGUN|RESIDENCE PORCH/H...| false|   false|0714|     007|  15|            67|     04A|        null|        null|2019|06/25/2019 04:19:...|    null|     null|    null|                      null|     null|           null|         null| null|                  null|            null|        null|\n",
       "|11727883|   JC312602|06/18/2019 11:30:...|025XX S TRUMBULL AVE|0810|               THEFT|           OVER $500|              STREET| false|   false|1024|     010|  22|            30|      06|        null|        null|2019|06/25/2019 04:19:...|    null|     null|    null|                      null|     null|           null|         null| null|                  null|            null|        null|\n",
       "|11727593|   JC312328|06/18/2019 11:30:...| 084XX S SAGINAW AVE|0486|             BATTERY|DOMESTIC BATTERY ...|           RESIDENCE| false|    true|0423|     004|   7|            46|     08B|        null|        null|2019|06/25/2019 04:19:...|    null|     null|    null|                      null|     null|           null|         null| null|                  null|            null|        null|\n",
       "|11727545|   JC312319|06/18/2019 11:20:...|     021XX W 35TH ST|2022|           NARCOTICS|       POSS: COCAINE|              STREET|  true|   false|0912|     009|  12|            59|      18|        null|        null|2019|06/25/2019 04:19:...|    null|     null|    null|                      null|     null|           null|         null| null|                  null|            null|        null|\n",
       "|11727554|   JC312308|06/18/2019 11:20:...| 013XX S KILDARE AVE|051A|             ASSAULT| AGGRAVATED: HANDGUN|           APARTMENT| false|   false|1011|     010|  24|            29|     04A|        null|        null|2019|06/25/2019 04:19:...|    null|     null|    null|                      null|     null|           null|         null| null|                  null|            null|        null|\n",
       "|11727632|   JC312316|06/18/2019 11:15:...| 085XX S PARNELL AVE|0486|             BATTERY|DOMESTIC BATTERY ...|           APARTMENT| false|    true|0622|     006|  21|            71|     08B|        null|        null|2019|06/25/2019 04:19:...|    null|     null|    null|                      null|     null|           null|         null| null|                  null|            null|        null|\n",
       "|11727619|   JC312309|06/18/2019 11:15:...|011XX S MICHIGAN AVE|0460|             BATTERY|              SIMPLE|            SIDEWALK| false|   false|0123|     001|   4|            32|     08B|        null|        null|2019|06/25/2019 04:19:...|    null|     null|    null|                      null|     null|           null|         null| null|                  null|            null|        null|\n",
       "|11727688|   JC312325|06/18/2019 11:15:...|  050XX W MADISON ST|0460|             BATTERY|              SIMPLE|            SIDEWALK| false|   false|1533|     015|  28|            25|     08B|        null|        null|2019|06/25/2019 04:19:...|    null|     null|    null|                      null|     null|           null|         null| null|                  null|            null|        null|\n",
       "|11727538|   JC312293|06/18/2019 11:08:...|   015XX S HOMAN AVE|0486|             BATTERY|DOMESTIC BATTERY ...|           APARTMENT|  true|    true|1021|     010|  24|            29|     08B|        null|        null|2019|06/25/2019 04:19:...|    null|     null|    null|                      null|     null|           null|         null| null|                  null|            null|        null|\n",
       "|11727609|   JC312341|06/18/2019 11:08:...|080XX S STONY ISL...|4650|       OTHER OFFENSE|SEX OFFENDER: FAI...|              STREET| false|   false|0411|     004|   8|            45|      26|        null|        null|2019|06/25/2019 04:19:...|    null|     null|    null|                      null|     null|           null|         null| null|                  null|            null|        null|\n",
       "|11727628|   JC312306|06/18/2019 11:00:...| 003XX W CHICAGO AVE|0460|             BATTERY|              SIMPLE|           CTA TRAIN| false|   false|1823|     018|  27|             8|     08B|        null|        null|2019|06/25/2019 04:19:...|    null|     null|    null|                      null|     null|           null|         null| null|                  null|            null|        null|\n",
       "|11729739|   JC314541|06/18/2019 11:00:...|079XX S WOODLAWN AVE|0330|             ROBBERY|          AGGRAVATED|               ALLEY| false|   false|0411|     004|   8|            45|      03|        null|        null|2019|06/25/2019 04:19:...|    null|     null|    null|                      null|     null|           null|         null| null|                  null|            null|        null|\n",
       "+--------+-----------+--------------------+--------------------+----+--------------------+--------------------+--------------------+------+--------+----+--------+----+--------------+--------+------------+------------+----+--------------------+--------+---------+--------+--------------------------+---------+---------------+-------------+-----+----------------------+----------------+------------+\n",
       "only showing top 20 rows"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.conf.set('spark.sql.repl.eagerEval.enabled', True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q : D√©terminer le bon [sch√©ma](https://sparkbyexamples.com/pyspark/pyspark-structtype-and-structfield/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Laisser Spark d√©terminer (pour nous) les bons types des cols est tr√®s co√ªteux parcq le df d'origine contient + de 5M rows => `spark.read.csv(path, header=True, InferSchema=True)` \n",
    "* Ns allons le faire manuellement (suivant notre intuition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type\n",
       "string    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Par d√©faut, Spark consid√®re toutes les cols en String\n",
    "# df.dtypes\n",
    "# pd.DataFrame(df.dtypes, columns=['col', 'type']).T\n",
    "pd.DataFrame(df.dtypes, columns=['col', 'type']).value_counts('type')\n",
    "# df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType, StringType, DoubleType, BooleanType, TimestampType, StructField, StructType "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('ID', IntegerType(), True), StructField('Case Number', StringType(), True), StructField('Date', StringType(), True), StructField('Block', StringType(), True), StructField('IUCR', StringType(), True), StructField('Primary Type', StringType(), True), StructField('Description', StringType(), True), StructField('Location Description', StringType(), True), StructField('Arrest', BooleanType(), True), StructField('Domestic', BooleanType(), True), StructField('Beat', IntegerType(), True), StructField('District', IntegerType(), True), StructField('Ward', IntegerType(), True), StructField('Community Area', IntegerType(), True), StructField('FBI Code', StringType(), True), StructField('X Coordinate', IntegerType(), True), StructField('Y Coordinate', IntegerType(), True), StructField('Year', IntegerType(), True), StructField('Updated On', StringType(), True), StructField('Latitude', DoubleType(), True), StructField('Longitude', DoubleType(), True), StructField('Location', StringType(), True), StructField('Historical Wards 2003-2015', IntegerType(), True), StructField('Zip Codes', IntegerType(), True), StructField('Community Areas', IntegerType(), True), StructField('Census Tracts', IntegerType(), True), StructField('Wards', IntegerType(), True), StructField('Boundaries - ZIP Codes', IntegerType(), True), StructField('Police Districts', IntegerType(), True), StructField('Police Beats', IntegerType(), True)])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cols = df.columns\n",
    "cols  = ['ID', 'Case Number', 'Date', 'Block', 'IUCR', 'Primary Type', 'Description', 'Location Description', 'Arrest', 'Domestic', 'Beat', 'District', 'Ward', 'Community Area', 'FBI Code', 'X Coordinate', 'Y Coordinate', 'Year', 'Updated On', 'Latitude', 'Longitude', 'Location', 'Historical Wards 2003-2015', 'Zip Codes', 'Community Areas', 'Census Tracts', 'Wards', 'Boundaries - ZIP Codes', 'Police Districts', 'Police Beats']\n",
    "\n",
    "types = [IntegerType(), StringType(), StringType(), StringType(), StringType(), StringType(), StringType(), StringType(), BooleanType(), BooleanType(), IntegerType(), IntegerType(), IntegerType(), IntegerType(), StringType(), IntegerType(), IntegerType(), IntegerType(), StringType(), DoubleType(), DoubleType(), StringType(), IntegerType(), IntegerType(), IntegerType(), IntegerType(), IntegerType(), IntegerType(), IntegerType(), IntegerType()]\n",
    "\n",
    "# les cols `Dates` sont conserv√©s en StringType et seront convertit en TimestampType parce qu'elle n√©cessitent un traitement sp√©cifique.\n",
    "\n",
    "# On cr√©e une liste de tuples avec `zip`\n",
    "cols_types = list(zip(cols, types))\n",
    "\n",
    "# On ajoute `True` dans les tuples √† l'aide de comprehension list\n",
    "schema = StructType([ StructField(i[0], i[1], True) for i in cols_types])\n",
    "schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ID', IntegerType()),\n",
       " ('Case Number', StringType()),\n",
       " ('Date', StringType()),\n",
       " ('Block', StringType()),\n",
       " ('IUCR', StringType()),\n",
       " ('Primary Type', StringType()),\n",
       " ('Description', StringType()),\n",
       " ('Location Description', StringType()),\n",
       " ('Arrest', BooleanType()),\n",
       " ('Domestic', BooleanType()),\n",
       " ('Beat', IntegerType()),\n",
       " ('District', IntegerType()),\n",
       " ('Ward', IntegerType()),\n",
       " ('Community Area', IntegerType()),\n",
       " ('FBI Code', StringType()),\n",
       " ('X Coordinate', IntegerType()),\n",
       " ('Y Coordinate', IntegerType()),\n",
       " ('Year', IntegerType()),\n",
       " ('Updated On', StringType()),\n",
       " ('Latitude', DoubleType()),\n",
       " ('Longitude', DoubleType()),\n",
       " ('Location', StringType()),\n",
       " ('Historical Wards 2003-2015', IntegerType()),\n",
       " ('Zip Codes', IntegerType()),\n",
       " ('Community Areas', IntegerType()),\n",
       " ('Census Tracts', IntegerType()),\n",
       " ('Wards', IntegerType()),\n",
       " ('Boundaries - ZIP Codes', IntegerType()),\n",
       " ('Police Districts', IntegerType()),\n",
       " ('Police Beats', IntegerType())]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[ID: int, Case Number: string, Date: string, Block: string, IUCR: string, Primary Type: string, Description: string, Location Description: string, Arrest: boolean, Domestic: boolean, Beat: int, District: int, Ward: int, Community Area: int, FBI Code: string, X Coordinate: int, Y Coordinate: int, Year: int, Updated On: string, Latitude: double, Longitude: double, Location: string, Historical Wards 2003-2015: int, Zip Codes: int, Community Areas: int, Census Tracts: int, Wards: int, Boundaries - ZIP Codes: int, Police Districts: int, Police Beats: int]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'file:///mnt/c/Users/bejao/OneDrive/data/Crimes-2001_to_present.txt'\n",
    "df = spark.read.csv(path, header=True, schema=schema)\n",
    "df\n",
    "# pd.DataFrame(df.dtypes, columns=['col', 'type']).value_counts('type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type\n",
       "string     20\n",
       "int         6\n",
       "boolean     1\n",
       "float       1\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "StructType([StructField(ID,StringType,true),\n",
    "    StructField(Case Number,StringType,true),StructField(Date,TimestampType,true),StructField(Block,StringType,true),StructField(IUCR,StringType,true),StructField(Primary Type,StringType,true),StructField(Description,StringType,true),StructField(Location Description,StringType,true),StructField(Arrest,StringType,true),StructField(Domestic,BooleanType,true),StructField(Beat,StringType,true),StructField(District,StringType,true),StructField(Ward,StringType,true),StructField(Community Area,StringType,true),StructField(FBI Code,StringType,true),StructField(X Coordinate,StringType,true),StructField(Y Coordinate,StringType,true),StructField(Year,IntegerType,true),StructField(Updated On,StringType,true),StructField(Latitude,DoubleType,true),StructField(Longitude,DoubleType,true),StructField(Location,StringType,true),StructField(Historical Wards 2003-2015,StringType,true),StructField(Zip Codes,StringType,true),StructField(Community Areas,StringType,true),StructField(Census Tracts,StringType,true),StructField(Wards,StringType,true),StructField(Boundaries - ZIP Codes,StringType,true),StructField(Police Districts,StringType,true),StructField(Police Beats,StringType,true))])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# head, tail, take, limit, collect, show ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xKL4Z0k7YyD7",
    "outputId": "0b3e3011-72c8-477c-9b26-c1fb8ce9f4fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(ID=11727746, Case Number='JC312349', Date='06/18/2019 11:55:00 PM', Block='0000X W 79TH ST', IUCR='0484', Primary Type='BATTERY', Description='PRO EMP HANDS NO/MIN INJURY', Location Description='CTA STATION', Arrest=False, Domestic=False, Beat=623, District=6, Ward=6, Community Area=44, FBI Code='08B', X Coordinate=None, Y Coordinate=None, Year=2019, Updated On='06/25/2019 04:19:57 PM', Latitude=None, Longitude=None, Location=None, Historical Wards 2003-2015=None, Zip Codes=None, Community Areas=None, Census Tracts=None, Wards=None, Boundaries - ZIP Codes=None, Police Districts=None, Police Beats=None),\n",
       " Row(ID=11728171, Case Number='JC312895', Date='06/18/2019 11:55:00 PM', Block='044XX S CHRISTIANA AVE', IUCR='1320', Primary Type='CRIMINAL DAMAGE', Description='TO VEHICLE', Location Description='STREET', Arrest=False, Domestic=False, Beat=821, District=8, Ward=14, Community Area=58, FBI Code='14', X Coordinate=None, Y Coordinate=None, Year=2019, Updated On='06/25/2019 04:19:57 PM', Latitude=None, Longitude=None, Location=None, Historical Wards 2003-2015=None, Zip Codes=None, Community Areas=None, Census Tracts=None, Wards=None, Boundaries - ZIP Codes=None, Police Districts=None, Police Beats=None),\n",
       " Row(ID=11728165, Case Number='JC312901', Date='06/18/2019 11:55:00 PM', Block='044XX S CHRISTIANA AVE', IUCR='1320', Primary Type='CRIMINAL DAMAGE', Description='TO VEHICLE', Location Description='STREET', Arrest=False, Domestic=False, Beat=821, District=8, Ward=14, Community Area=58, FBI Code='14', X Coordinate=None, Y Coordinate=None, Year=2019, Updated On='06/25/2019 04:19:57 PM', Latitude=None, Longitude=None, Location=None, Historical Wards 2003-2015=None, Zip Codes=None, Community Areas=None, Census Tracts=None, Wards=None, Boundaries - ZIP Codes=None, Police Districts=None, Police Beats=None),\n",
       " Row(ID=11727579, Case Number='JC312360', Date='06/18/2019 11:50:00 PM', Block='076XX S COTTAGE GROVE AVE', IUCR='0470', Primary Type='PUBLIC PEACE VIOLATION', Description='RECKLESS CONDUCT', Location Description='STREET', Arrest=True, Domestic=False, Beat=624, District=6, Ward=6, Community Area=69, FBI Code='24', X Coordinate=None, Y Coordinate=None, Year=2019, Updated On='06/25/2019 04:19:57 PM', Latitude=None, Longitude=None, Location=None, Historical Wards 2003-2015=None, Zip Codes=None, Community Areas=None, Census Tracts=None, Wards=None, Boundaries - ZIP Codes=None, Police Districts=None, Police Beats=None),\n",
       " Row(ID=11727572, Case Number='JC312333', Date='06/18/2019 11:50:00 PM', Block='040XX W SCHOOL ST', IUCR='0460', Primary Type='BATTERY', Description='SIMPLE', Location Description='BAR OR TAVERN', Arrest=False, Domestic=False, Beat=1731, District=17, Ward=30, Community Area=16, FBI Code='08B', X Coordinate=None, Y Coordinate=None, Year=2019, Updated On='06/25/2019 04:19:57 PM', Latitude=None, Longitude=None, Location=None, Historical Wards 2003-2015=None, Zip Codes=None, Community Areas=None, Census Tracts=None, Wards=None, Boundaries - ZIP Codes=None, Police Districts=None, Police Beats=None)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# limit() retourne un df-spark que ns pouvons afficher avec show, que je peux convertir en df-pandas => affichage plus agr√©able \n",
    "# https://sparkbyexamples.com/pyspark/convert-pyspark-dataframe-to-pandas/\n",
    "# df.limit(5).toPandas()\n",
    "\n",
    "# pd.DataFrame(df.head(5), columns=df.columns)\n",
    "# df.head(5) #  contrairement √† show(), head() affiche une liste de Row\n",
    "# df.take(5) #  idem\n",
    "# type(df.head(5)) #  liste de row (√† la spark)\n",
    "# type(df.head(5)[0])\n",
    "\n",
    "# df.limit(5).collect() #  collect apr√®s limit retourne une liste de Row\n",
    "df.collect() # ne pas utiliser parcq retourner tt le dataset (si vs avez du vrai Big Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CvzaKhTUYeo6",
    "outputId": "35261af7-8512-4086-a02e-e85ada57938d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Case Number</th>\n",
       "      <th>Date</th>\n",
       "      <th>Block</th>\n",
       "      <th>IUCR</th>\n",
       "      <th>Primary Type</th>\n",
       "      <th>Description</th>\n",
       "      <th>Location Description</th>\n",
       "      <th>Arrest</th>\n",
       "      <th>Domestic</th>\n",
       "      <th>...</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Location</th>\n",
       "      <th>Historical Wards 2003-2015</th>\n",
       "      <th>Zip Codes</th>\n",
       "      <th>Community Areas</th>\n",
       "      <th>Census Tracts</th>\n",
       "      <th>Wards</th>\n",
       "      <th>Boundaries - ZIP Codes</th>\n",
       "      <th>Police Districts</th>\n",
       "      <th>Police Beats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1403263</td>\n",
       "      <td>G117094</td>\n",
       "      <td>01/01/2001 12:00:00 AM</td>\n",
       "      <td>084XX S PRAIRIE AV</td>\n",
       "      <td>1120</td>\n",
       "      <td>DECEPTIVE PRACTICE</td>\n",
       "      <td>FORGERY</td>\n",
       "      <td>BANK</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>-87.617741</td>\n",
       "      <td>(41.741163326, -87.617740827)</td>\n",
       "      <td>31</td>\n",
       "      <td>21546</td>\n",
       "      <td>40</td>\n",
       "      <td>406</td>\n",
       "      <td>32</td>\n",
       "      <td>61</td>\n",
       "      <td>20</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1352564</td>\n",
       "      <td>G055473</td>\n",
       "      <td>01/01/2001 12:00:00 AM</td>\n",
       "      <td>018XX N TALMAN AV</td>\n",
       "      <td>0820</td>\n",
       "      <td>THEFT</td>\n",
       "      <td>$500 AND UNDER</td>\n",
       "      <td>STREET</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>-87.693605</td>\n",
       "      <td>(41.914955409, -87.693605188)</td>\n",
       "      <td>24</td>\n",
       "      <td>22535</td>\n",
       "      <td>23</td>\n",
       "      <td>180</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1313893</td>\n",
       "      <td>G000035</td>\n",
       "      <td>01/01/2001 12:00:00 AM</td>\n",
       "      <td>027XX W NELSON ST</td>\n",
       "      <td>1310</td>\n",
       "      <td>CRIMINAL DAMAGE</td>\n",
       "      <td>TO PROPERTY</td>\n",
       "      <td>RESIDENCE</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>-87.697098</td>\n",
       "      <td>(41.936549915, -87.697097823)</td>\n",
       "      <td>24</td>\n",
       "      <td>21538</td>\n",
       "      <td>22</td>\n",
       "      <td>467</td>\n",
       "      <td>20</td>\n",
       "      <td>39</td>\n",
       "      <td>7</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1374123</td>\n",
       "      <td>G083329</td>\n",
       "      <td>01/01/2001 12:00:00 AM</td>\n",
       "      <td>045XX S LAPORTE AV</td>\n",
       "      <td>0820</td>\n",
       "      <td>THEFT</td>\n",
       "      <td>$500 AND UNDER</td>\n",
       "      <td>STREET</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>-87.747061</td>\n",
       "      <td>(41.810679064, -87.747061323)</td>\n",
       "      <td>35</td>\n",
       "      <td>22268</td>\n",
       "      <td>53</td>\n",
       "      <td>604</td>\n",
       "      <td>28</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1329588</td>\n",
       "      <td>G025242</td>\n",
       "      <td>01/01/2001 12:00:00 AM</td>\n",
       "      <td>061XX S COTTAGE GROVE AV</td>\n",
       "      <td>0820</td>\n",
       "      <td>THEFT</td>\n",
       "      <td>$500 AND UNDER</td>\n",
       "      <td>STREET</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>-87.606155</td>\n",
       "      <td>(41.783961993, -87.606155349)</td>\n",
       "      <td>53</td>\n",
       "      <td>22260</td>\n",
       "      <td>9</td>\n",
       "      <td>471</td>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "      <td>18</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID Case Number                    Date                     Block  \\\n",
       "0  1403263     G117094  01/01/2001 12:00:00 AM        084XX S PRAIRIE AV   \n",
       "1  1352564     G055473  01/01/2001 12:00:00 AM         018XX N TALMAN AV   \n",
       "2  1313893     G000035  01/01/2001 12:00:00 AM         027XX W NELSON ST   \n",
       "3  1374123     G083329  01/01/2001 12:00:00 AM        045XX S LAPORTE AV   \n",
       "4  1329588     G025242  01/01/2001 12:00:00 AM  061XX S COTTAGE GROVE AV   \n",
       "\n",
       "   IUCR        Primary Type     Description Location Description  Arrest  \\\n",
       "0  1120  DECEPTIVE PRACTICE         FORGERY                 BANK   False   \n",
       "1  0820               THEFT  $500 AND UNDER               STREET   False   \n",
       "2  1310     CRIMINAL DAMAGE     TO PROPERTY            RESIDENCE   False   \n",
       "3  0820               THEFT  $500 AND UNDER               STREET   False   \n",
       "4  0820               THEFT  $500 AND UNDER               STREET   False   \n",
       "\n",
       "   Domestic  ...  Longitude                       Location  \\\n",
       "0     False  ... -87.617741  (41.741163326, -87.617740827)   \n",
       "1     False  ... -87.693605  (41.914955409, -87.693605188)   \n",
       "2     False  ... -87.697098  (41.936549915, -87.697097823)   \n",
       "3     False  ... -87.747061  (41.810679064, -87.747061323)   \n",
       "4     False  ... -87.606155  (41.783961993, -87.606155349)   \n",
       "\n",
       "  Historical Wards 2003-2015 Zip Codes Community Areas  Census Tracts  Wards  \\\n",
       "0                         31     21546              40            406     32   \n",
       "1                         24     22535              23            180     41   \n",
       "2                         24     21538              22            467     20   \n",
       "3                         35     22268              53            604     28   \n",
       "4                         53     22260               9            471      4   \n",
       "\n",
       "   Boundaries - ZIP Codes Police Districts  Police Beats  \n",
       "0                      61               20           241  \n",
       "1                       1                7           171  \n",
       "2                      39                7           174  \n",
       "3                       7               13           112  \n",
       "4                      60               18           275  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.tail(5) \n",
    "import pandas as pd\n",
    "pd.DataFrame(df.tail(5), columns=df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eAwb9_uPWg9o",
    "outputId": "a0fa95c9-e441-4cb1-9251-fdd37b95f0df"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6899950"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.columns\n",
    "# type(df.columns) #  liste\n",
    "# len(df.columns)\n",
    "df.count()   # nb de ligne : 6899950"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [cache or persist](https://stackoverflow.com/questions/26870537/what-is-the-difference-between-cache-and-persist?utm_medium=organic&utm_source=google_rich_qa&utm_campaign=google_rich_qa) ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Comme ns allons r√©aliser de nombreuses op√© sur le `df`, il vaut mieux le mettre en `cache` ce qui permettra de gagner du temps de calcul. Le `df` sera stock√© en m√©moire vive\n",
    "* The difference between `cache` and `persist` is purely syntactic. `cache` is a synonym of `persist` or `persist(MEMORY_ONLY)`. But Persist() We can save the intermediate results in 5 storage levels : `MEMORY_ONLY`, `MEMORY_AND_DISK`, `MEMORY_ONLY_SER`, `MEMORY_AND_DISK_SER`, `DISK_ONLY`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[ID: int, Case Number: string, Date: string, Block: string, IUCR: string, Primary Type: string, Description: string, Location Description: string, Arrest: boolean, Domestic: boolean, Beat: int, District: int, Ward: int, Community Area: int, FBI Code: string, X Coordinate: int, Y Coordinate: int, Year: int, Updated On: string, Latitude: double, Longitude: double, Location: string, Historical Wards 2003-2015: int, Zip Codes: int, Community Areas: int, Census Tracts: int, Wards: int, Boundaries - ZIP Codes: int, Police Districts: int, Police Beats: int]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.cache()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [describe](https://databricks.com/fr/blog/2015/06/02/statistical-and-mathematical-functions-with-dataframes-in-spark.html) & summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* L'op√© suivante va mettre approx 3 min et r√©aliser 14 `tasks` !\n",
    "* Que signifie `stage` dans Spark ?  : [sackoverflow](https://stackoverflow.com/questions/32994980/what-does-stage-mean-in-the-spark-logs)\n",
    "* Que signifie tasks  : [mallikarjuna](https://mallikarjuna_g.gitbooks.io/spark/content/spark-taskscheduler-tasks.html), [stackoverflow](https://stackoverflow.com/questions/25276409/what-is-a-task-in-spark-how-does-the-spark-worker-execute-the-jar-file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "5l8t4oOhiOI1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, ID: string, Case Number: string, Date: string, Block: string, IUCR: string, Primary Type: string, Description: string, Location Description: string, Beat: string, District: string, Ward: string, Community Area: string, FBI Code: string, X Coordinate: string, Y Coordinate: string, Year: string, Updated On: string, Latitude: string, Longitude: string, Location: string, Historical Wards 2003-2015: string, Zip Codes: string, Community Areas: string, Census Tracts: string, Wards: string, Boundaries - ZIP Codes: string, Police Districts: string, Police Beats: string]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_desc = df.describe()\n",
    "df_desc\n",
    "# df_desc.show()\n",
    "# df_desc = df.describe().toPandas()\n",
    "# df_desc.set_index('summary').T \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* L'op√© suivante va mettre approx 7 min et r√©aliser 14 `tasks` !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "VRy8Yy6OicEV"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, ID: string, Case Number: string, Date: string, Block: string, IUCR: string, Primary Type: string, Description: string, Location Description: string, Arrest: string, Domestic: string, Beat: string, District: string, Ward: string, Community Area: string, FBI Code: string, X Coordinate: string, Y Coordinate: string, Year: string, Updated On: string, Latitude: string, Longitude: string, Location: string, Historical Wards 2003-2015: string, Zip Codes: string, Community Areas: string, Census Tracts: string, Wards: string, Boundaries - ZIP Codes: string, Police Districts: string, Police Beats: string]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing values : [sparkByExamples](https://sparkbyexamples.com/pyspark/pyspark-find-count-of-null-none-nan-values/), [stackoverflow](https://stackoverflow.com/questions/44413132/count-the-number-of-missing-values-in-a-dataframe-spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>ID</th>\n",
       "      <th>Case Number</th>\n",
       "      <th>Date</th>\n",
       "      <th>Block</th>\n",
       "      <th>IUCR</th>\n",
       "      <th>Primary Type</th>\n",
       "      <th>Description</th>\n",
       "      <th>Location Description</th>\n",
       "      <th>Arrest</th>\n",
       "      <th>...</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Location</th>\n",
       "      <th>Historical Wards 2003-2015</th>\n",
       "      <th>Zip Codes</th>\n",
       "      <th>Community Areas</th>\n",
       "      <th>Census Tracts</th>\n",
       "      <th>Wards</th>\n",
       "      <th>Boundaries - ZIP Codes</th>\n",
       "      <th>Police Districts</th>\n",
       "      <th>Police Beats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count</td>\n",
       "      <td>6899950</td>\n",
       "      <td>6899946</td>\n",
       "      <td>6899950</td>\n",
       "      <td>6899950</td>\n",
       "      <td>6899950</td>\n",
       "      <td>6899950</td>\n",
       "      <td>6899950</td>\n",
       "      <td>6894787</td>\n",
       "      <td>6899950</td>\n",
       "      <td>...</td>\n",
       "      <td>6811819</td>\n",
       "      <td>6811819</td>\n",
       "      <td>6792027</td>\n",
       "      <td>6811819</td>\n",
       "      <td>6794741</td>\n",
       "      <td>6796898</td>\n",
       "      <td>6794853</td>\n",
       "      <td>6794788</td>\n",
       "      <td>6795817</td>\n",
       "      <td>6795840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows √ó 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  summary       ID Case Number     Date    Block     IUCR Primary Type  \\\n",
       "0   count  6899950     6899946  6899950  6899950  6899950      6899950   \n",
       "\n",
       "  Description Location Description   Arrest  ... Longitude Location  \\\n",
       "0     6899950              6894787  6899950  ...   6811819  6811819   \n",
       "\n",
       "  Historical Wards 2003-2015 Zip Codes Community Areas Census Tracts    Wards  \\\n",
       "0                    6792027   6811819         6794741       6796898  6794853   \n",
       "\n",
       "  Boundaries - ZIP Codes Police Districts Police Beats  \n",
       "0                6794788          6795817      6795840  \n",
       "\n",
       "[1 rows x 31 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.summary('count').toPandas().T\n",
    "\n",
    "# [{c:df.filter(df[c].isNull()).count()} for c in df.columns]\n",
    "\n",
    "from pyspark.sql.functions import col,isnan, when, count\n",
    "df.select([count(when(col(c).isNull(), c)).alias(c) for c in df.columns]   ).show()\n",
    "# df_na.T.sort_values(by = 0, ascending=False)/df.count() * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unique values : [SparkByExample](https://sparkbyexamples.com/pyspark/pyspark-distinct-to-drop-duplicates/), [stackoverflow](https://stackoverflow.com/questions/39383557/show-distinct-column-values-in-pyspark-dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Case Number</th>\n",
       "      <th>Date</th>\n",
       "      <th>Block</th>\n",
       "      <th>IUCR</th>\n",
       "      <th>Primary Type</th>\n",
       "      <th>Description</th>\n",
       "      <th>Location Description</th>\n",
       "      <th>Arrest</th>\n",
       "      <th>Domestic</th>\n",
       "      <th>...</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Location</th>\n",
       "      <th>Historical Wards 2003-2015</th>\n",
       "      <th>Zip Codes</th>\n",
       "      <th>Community Areas</th>\n",
       "      <th>Census Tracts</th>\n",
       "      <th>Wards</th>\n",
       "      <th>Boundaries - ZIP Codes</th>\n",
       "      <th>Police Districts</th>\n",
       "      <th>Police Beats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6899950.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>6899536.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2773693.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60331.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>402.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>380.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>180.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>862311.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>864048.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>802.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>278.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows √ó 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID  Case Number       Date    Block   IUCR  Primary Type  \\\n",
       "0   6899950.0          NaN        NaN      NaN    NaN           NaN   \n",
       "1         NaN    6899536.0        NaN      NaN    NaN           NaN   \n",
       "2         NaN          NaN  2773693.0      NaN    NaN           NaN   \n",
       "3         NaN          NaN        NaN  60331.0    NaN           NaN   \n",
       "4         NaN          NaN        NaN      NaN  402.0           NaN   \n",
       "5         NaN          NaN        NaN      NaN    NaN          35.0   \n",
       "6         NaN          NaN        NaN      NaN    NaN           NaN   \n",
       "7         NaN          NaN        NaN      NaN    NaN           NaN   \n",
       "8         NaN          NaN        NaN      NaN    NaN           NaN   \n",
       "9         NaN          NaN        NaN      NaN    NaN           NaN   \n",
       "10        NaN          NaN        NaN      NaN    NaN           NaN   \n",
       "11        NaN          NaN        NaN      NaN    NaN           NaN   \n",
       "12        NaN          NaN        NaN      NaN    NaN           NaN   \n",
       "13        NaN          NaN        NaN      NaN    NaN           NaN   \n",
       "14        NaN          NaN        NaN      NaN    NaN           NaN   \n",
       "15        NaN          NaN        NaN      NaN    NaN           NaN   \n",
       "16        NaN          NaN        NaN      NaN    NaN           NaN   \n",
       "17        NaN          NaN        NaN      NaN    NaN           NaN   \n",
       "18        NaN          NaN        NaN      NaN    NaN           NaN   \n",
       "19        NaN          NaN        NaN      NaN    NaN           NaN   \n",
       "20        NaN          NaN        NaN      NaN    NaN           NaN   \n",
       "21        NaN          NaN        NaN      NaN    NaN           NaN   \n",
       "22        NaN          NaN        NaN      NaN    NaN           NaN   \n",
       "23        NaN          NaN        NaN      NaN    NaN           NaN   \n",
       "24        NaN          NaN        NaN      NaN    NaN           NaN   \n",
       "25        NaN          NaN        NaN      NaN    NaN           NaN   \n",
       "26        NaN          NaN        NaN      NaN    NaN           NaN   \n",
       "27        NaN          NaN        NaN      NaN    NaN           NaN   \n",
       "28        NaN          NaN        NaN      NaN    NaN           NaN   \n",
       "29        NaN          NaN        NaN      NaN    NaN           NaN   \n",
       "\n",
       "    Description  Location Description  Arrest  Domestic  ...  Longitude  \\\n",
       "0           NaN                   NaN     NaN       NaN  ...        NaN   \n",
       "1           NaN                   NaN     NaN       NaN  ...        NaN   \n",
       "2           NaN                   NaN     NaN       NaN  ...        NaN   \n",
       "3           NaN                   NaN     NaN       NaN  ...        NaN   \n",
       "4           NaN                   NaN     NaN       NaN  ...        NaN   \n",
       "5           NaN                   NaN     NaN       NaN  ...        NaN   \n",
       "6         380.0                   NaN     NaN       NaN  ...        NaN   \n",
       "7           NaN                 180.0     NaN       NaN  ...        NaN   \n",
       "8           NaN                   NaN     2.0       NaN  ...        NaN   \n",
       "9           NaN                   NaN     NaN       2.0  ...        NaN   \n",
       "10          NaN                   NaN     NaN       NaN  ...        NaN   \n",
       "11          NaN                   NaN     NaN       NaN  ...        NaN   \n",
       "12          NaN                   NaN     NaN       NaN  ...        NaN   \n",
       "13          NaN                   NaN     NaN       NaN  ...        NaN   \n",
       "14          NaN                   NaN     NaN       NaN  ...        NaN   \n",
       "15          NaN                   NaN     NaN       NaN  ...        NaN   \n",
       "16          NaN                   NaN     NaN       NaN  ...        NaN   \n",
       "17          NaN                   NaN     NaN       NaN  ...        NaN   \n",
       "18          NaN                   NaN     NaN       NaN  ...        NaN   \n",
       "19          NaN                   NaN     NaN       NaN  ...        NaN   \n",
       "20          NaN                   NaN     NaN       NaN  ...   862311.0   \n",
       "21          NaN                   NaN     NaN       NaN  ...        NaN   \n",
       "22          NaN                   NaN     NaN       NaN  ...        NaN   \n",
       "23          NaN                   NaN     NaN       NaN  ...        NaN   \n",
       "24          NaN                   NaN     NaN       NaN  ...        NaN   \n",
       "25          NaN                   NaN     NaN       NaN  ...        NaN   \n",
       "26          NaN                   NaN     NaN       NaN  ...        NaN   \n",
       "27          NaN                   NaN     NaN       NaN  ...        NaN   \n",
       "28          NaN                   NaN     NaN       NaN  ...        NaN   \n",
       "29          NaN                   NaN     NaN       NaN  ...        NaN   \n",
       "\n",
       "    Location  Historical Wards 2003-2015  Zip Codes  Community Areas  \\\n",
       "0        NaN                         NaN        NaN              NaN   \n",
       "1        NaN                         NaN        NaN              NaN   \n",
       "2        NaN                         NaN        NaN              NaN   \n",
       "3        NaN                         NaN        NaN              NaN   \n",
       "4        NaN                         NaN        NaN              NaN   \n",
       "5        NaN                         NaN        NaN              NaN   \n",
       "6        NaN                         NaN        NaN              NaN   \n",
       "7        NaN                         NaN        NaN              NaN   \n",
       "8        NaN                         NaN        NaN              NaN   \n",
       "9        NaN                         NaN        NaN              NaN   \n",
       "10       NaN                         NaN        NaN              NaN   \n",
       "11       NaN                         NaN        NaN              NaN   \n",
       "12       NaN                         NaN        NaN              NaN   \n",
       "13       NaN                         NaN        NaN              NaN   \n",
       "14       NaN                         NaN        NaN              NaN   \n",
       "15       NaN                         NaN        NaN              NaN   \n",
       "16       NaN                         NaN        NaN              NaN   \n",
       "17       NaN                         NaN        NaN              NaN   \n",
       "18       NaN                         NaN        NaN              NaN   \n",
       "19       NaN                         NaN        NaN              NaN   \n",
       "20       NaN                         NaN        NaN              NaN   \n",
       "21  864048.0                         NaN        NaN              NaN   \n",
       "22       NaN                        54.0        NaN              NaN   \n",
       "23       NaN                         NaN       84.0              NaN   \n",
       "24       NaN                         NaN        NaN             78.0   \n",
       "25       NaN                         NaN        NaN              NaN   \n",
       "26       NaN                         NaN        NaN              NaN   \n",
       "27       NaN                         NaN        NaN              NaN   \n",
       "28       NaN                         NaN        NaN              NaN   \n",
       "29       NaN                         NaN        NaN              NaN   \n",
       "\n",
       "    Census Tracts  Wards  Boundaries - ZIP Codes  Police Districts  \\\n",
       "0             NaN    NaN                     NaN               NaN   \n",
       "1             NaN    NaN                     NaN               NaN   \n",
       "2             NaN    NaN                     NaN               NaN   \n",
       "3             NaN    NaN                     NaN               NaN   \n",
       "4             NaN    NaN                     NaN               NaN   \n",
       "5             NaN    NaN                     NaN               NaN   \n",
       "6             NaN    NaN                     NaN               NaN   \n",
       "7             NaN    NaN                     NaN               NaN   \n",
       "8             NaN    NaN                     NaN               NaN   \n",
       "9             NaN    NaN                     NaN               NaN   \n",
       "10            NaN    NaN                     NaN               NaN   \n",
       "11            NaN    NaN                     NaN               NaN   \n",
       "12            NaN    NaN                     NaN               NaN   \n",
       "13            NaN    NaN                     NaN               NaN   \n",
       "14            NaN    NaN                     NaN               NaN   \n",
       "15            NaN    NaN                     NaN               NaN   \n",
       "16            NaN    NaN                     NaN               NaN   \n",
       "17            NaN    NaN                     NaN               NaN   \n",
       "18            NaN    NaN                     NaN               NaN   \n",
       "19            NaN    NaN                     NaN               NaN   \n",
       "20            NaN    NaN                     NaN               NaN   \n",
       "21            NaN    NaN                     NaN               NaN   \n",
       "22            NaN    NaN                     NaN               NaN   \n",
       "23            NaN    NaN                     NaN               NaN   \n",
       "24            NaN    NaN                     NaN               NaN   \n",
       "25          802.0    NaN                     NaN               NaN   \n",
       "26            NaN   51.0                     NaN               NaN   \n",
       "27            NaN    NaN                    62.0               NaN   \n",
       "28            NaN    NaN                     NaN              26.0   \n",
       "29            NaN    NaN                     NaN               NaN   \n",
       "\n",
       "    Police Beats  \n",
       "0            NaN  \n",
       "1            NaN  \n",
       "2            NaN  \n",
       "3            NaN  \n",
       "4            NaN  \n",
       "5            NaN  \n",
       "6            NaN  \n",
       "7            NaN  \n",
       "8            NaN  \n",
       "9            NaN  \n",
       "10           NaN  \n",
       "11           NaN  \n",
       "12           NaN  \n",
       "13           NaN  \n",
       "14           NaN  \n",
       "15           NaN  \n",
       "16           NaN  \n",
       "17           NaN  \n",
       "18           NaN  \n",
       "19           NaN  \n",
       "20           NaN  \n",
       "21           NaN  \n",
       "22           NaN  \n",
       "23           NaN  \n",
       "24           NaN  \n",
       "25           NaN  \n",
       "26           NaN  \n",
       "27           NaN  \n",
       "28           NaN  \n",
       "29         278.0  \n",
       "\n",
       "[30 rows x 30 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unique = df.select('*').distinct()\n",
    "# .show(10, truncate=False)\n",
    "\n",
    "\n",
    "[{c:df.select(c).distinct().count()} for c in df.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [value_counts](https://napsterinblue.github.io/notes/spark/sparksql/value_counts/)   [stackoverflow](https://stackoverflow.com/questions/51063624/whats-the-equivalent-of-pandas-value-counts-in-pyspark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/01/08 01:39:27 WARN memory.MemoryStore: Not enough space to cache rdd_19_3 in memory! (computed 29.2 MiB so far)\n",
      "22/01/08 01:39:27 WARN memory.MemoryStore: Not enough space to cache rdd_19_2 in memory! (computed 29.7 MiB so far)\n",
      "22/01/08 01:39:27 WARN memory.MemoryStore: Not enough space to cache rdd_19_4 in memory! (computed 29.4 MiB so far)\n",
      "22/01/08 01:39:27 WARN memory.MemoryStore: Not enough space to cache rdd_19_5 in memory! (computed 29.1 MiB so far)\n",
      "22/01/08 01:39:28 WARN memory.MemoryStore: Not enough space to cache rdd_19_6 in memory! (computed 29.4 MiB so far)\n",
      "22/01/08 01:39:28 WARN memory.MemoryStore: Not enough space to cache rdd_19_7 in memory! (computed 29.6 MiB so far)\n",
      "22/01/08 01:39:28 WARN memory.MemoryStore: Not enough space to cache rdd_19_8 in memory! (computed 29.6 MiB so far)\n",
      "22/01/08 01:39:28 WARN memory.MemoryStore: Not enough space to cache rdd_19_9 in memory! (computed 29.6 MiB so far)\n",
      "22/01/08 01:39:28 WARN memory.MemoryStore: Not enough space to cache rdd_19_10 in memory! (computed 29.5 MiB so far)\n",
      "22/01/08 01:39:29 WARN memory.MemoryStore: Not enough space to cache rdd_19_11 in memory! (computed 29.5 MiB so far)\n",
      "[Stage 74:================================================>       (12 + 2) / 14]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------+\n",
      "|   Primary Type|  count|\n",
      "+---------------+-------+\n",
      "|          THEFT|1453743|\n",
      "|        BATTERY|1260831|\n",
      "|CRIMINAL DAMAGE| 786698|\n",
      "|      NARCOTICS| 719559|\n",
      "|        ASSAULT| 430537|\n",
      "+---------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/01/08 17:06:36 WARN spark.HeartbeatReceiver: Removing executor driver with no recent heartbeats: 45942743 ms exceeds timeout 120000 ms\n",
      "22/01/08 17:06:36 WARN netty.NettyRpcEnv: Ignored message: true\n",
      "22/01/08 17:06:36 WARN netty.NettyRpcEnv: Ignored message: true\n",
      "22/01/08 17:06:36 WARN netty.NettyRpcEnv: Ignored message: true\n",
      "22/01/08 17:06:36 WARN netty.NettyRpcEnv: Ignored message: true\n",
      "22/01/08 17:06:36 WARN netty.NettyRpcEnv: Ignored message: true\n",
      "22/01/08 17:06:36 WARN netty.NettyRpcEnv: Ignored message: true\n",
      "22/01/08 17:06:36 WARN netty.NettyRpcEnv: Ignored message: true\n",
      "22/01/08 17:06:36 WARN netty.NettyRpcEnv: Ignored message: true\n",
      "22/01/08 17:06:36 WARN netty.NettyRpcEnv: Ignored message: true\n",
      "22/01/08 17:06:36 WARN netty.NettyRpcEnv: Ignored message: true\n",
      "22/01/08 17:06:36 WARN netty.NettyRpcEnv: Ignored message: true\n",
      "22/01/08 17:06:36 WARN netty.NettyRpcEnv: Ignored message: true\n",
      "22/01/08 17:06:36 WARN netty.NettyRpcEnv: Ignored message: true\n",
      "22/01/08 17:06:36 WARN netty.NettyRpcEnv: Ignored message: true\n",
      "22/01/08 17:06:36 WARN spark.SparkContext: Killing executors is not supported by current scheduler.\n"
     ]
    }
   ],
   "source": [
    "# import pyspark.sql.functions as F     \n",
    "\n",
    "import pyspark.sql.functions as func\n",
    "count_cl = df.count()\n",
    "df \\\n",
    ".groupBy('Primary Type') \\\n",
    ".count() \\\n",
    ".withColumn('%', func.round((func.col('count')/count_cl)*100,2)) \\\n",
    ".orderBy('count', ascending=False)\n",
    "\n",
    "df_value_counts.show(5)\n",
    "\n",
    "df.groupby('category').agg(\n",
    "    (F.count('Primary Type')).alias('count'),\n",
    "    (F.count('Primary Type') / df.count()).alias('percentage')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8qf-TmnsBgXd"
   },
   "source": [
    "# Working with columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WvOfJmzhf0kG"
   },
   "source": [
    "**Q : Acc√©der √† la col `District` et `Case Number`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>District</th><th>Case Number</th></tr>\n",
       "<tr><td>006</td><td>JC312349</td></tr>\n",
       "<tr><td>008</td><td>JC312895</td></tr>\n",
       "<tr><td>008</td><td>JC312901</td></tr>\n",
       "<tr><td>006</td><td>JC312360</td></tr>\n",
       "<tr><td>017</td><td>JC312333</td></tr>\n",
       "<tr><td>005</td><td>JC312367</td></tr>\n",
       "<tr><td>024</td><td>JC312338</td></tr>\n",
       "<tr><td>005</td><td>JC312327</td></tr>\n",
       "<tr><td>007</td><td>JC312317</td></tr>\n",
       "<tr><td>010</td><td>JC312602</td></tr>\n",
       "<tr><td>004</td><td>JC312328</td></tr>\n",
       "<tr><td>009</td><td>JC312319</td></tr>\n",
       "<tr><td>010</td><td>JC312308</td></tr>\n",
       "<tr><td>006</td><td>JC312316</td></tr>\n",
       "<tr><td>001</td><td>JC312309</td></tr>\n",
       "<tr><td>015</td><td>JC312325</td></tr>\n",
       "<tr><td>010</td><td>JC312293</td></tr>\n",
       "<tr><td>004</td><td>JC312341</td></tr>\n",
       "<tr><td>018</td><td>JC312306</td></tr>\n",
       "<tr><td>004</td><td>JC314541</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "+--------+-----------+\n",
       "|District|Case Number|\n",
       "+--------+-----------+\n",
       "|     006|   JC312349|\n",
       "|     008|   JC312895|\n",
       "|     008|   JC312901|\n",
       "|     006|   JC312360|\n",
       "|     017|   JC312333|\n",
       "|     005|   JC312367|\n",
       "|     024|   JC312338|\n",
       "|     005|   JC312327|\n",
       "|     007|   JC312317|\n",
       "|     010|   JC312602|\n",
       "|     004|   JC312328|\n",
       "|     009|   JC312319|\n",
       "|     010|   JC312308|\n",
       "|     006|   JC312316|\n",
       "|     001|   JC312309|\n",
       "|     015|   JC312325|\n",
       "|     010|   JC312293|\n",
       "|     004|   JC312341|\n",
       "|     018|   JC312306|\n",
       "|     004|   JC314541|\n",
       "+--------+-----------+\n",
       "only showing top 20 rows"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.columns\n",
    "\n",
    "## Acc√©s √† une seule col  \n",
    "# df.District, type(_)\n",
    "# df['Case Number'], type(_)\n",
    "\n",
    "## L'ensemble de ces √©critures sont √©quivalentes \n",
    "# df.select('District')\n",
    "# df.select('Case Number')\n",
    "# df.select(df.District)\n",
    "# df.select(F.col('District'))\n",
    "\n",
    "## Acc√©s √† plusieurs col  \n",
    "df.select(['District', 'Case Number'])\n",
    "df.select('District', 'Case Number')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WvOfJmzhf0kG"
   },
   "source": [
    "**Q : Display only the first 5 rows of the column name IUCR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "lX6Weo0oOTYe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|IUCR|\n",
      "+----+\n",
      "|0484|\n",
      "|1320|\n",
      "|1320|\n",
      "|0470|\n",
      "|0460|\n",
      "+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('IUCR').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A4u5vp73gEtB"
   },
   "source": [
    "**Q : Display only the first 4 rows of the column names Case Number, Date and Arrest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "phi0-USnOTYe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+------+\n",
      "|Case Number|                Date|Arrest|\n",
      "+-----------+--------------------+------+\n",
      "|   JC312349|06/18/2019 11:55:...| false|\n",
      "|   JC312895|06/18/2019 11:55:...| false|\n",
      "|   JC312901|06/18/2019 11:55:...| false|\n",
      "|   JC312360|06/18/2019 11:50:...|  true|\n",
      "+-----------+--------------------+------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(['Case Number', 'Date', 'Arrest']).show(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GKnmLXJWr35c"
   },
   "source": [
    "**Q : Add a column with name One, with entries all 1s [SparkByExamples](https://sparkbyexamples.com/spark/spark-add-new-column-to-dataframe/)  [stackoverflow](https://stackoverflow.com/questions/55382401/how-to-add-multiple-empty-columns-to-a-pyspark-dataframe-at-specific-locations)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "hpn7bhmgOTYf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'One[dtype]'>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = df.withColumn('One', F.lit(1))   # `lit` pour dire `litteral` \n",
    "# df.select('District', 'One').show(5)\n",
    "# df\n",
    "df.One.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BKV2ymA2uI2h"
   },
   "source": [
    "**Q : Remove the column One Or multiple columns**  [SparkByExamples](https://sparkbyexamples.com/pyspark/pyspark-drop-column-from-dataframe/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "sLiWTg2HOTYf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>Date</th><th>IUCR</th><th>Primary Type</th><th>Description</th><th>Location Description</th><th>Arrest</th><th>Domestic</th><th>Beat</th><th>District</th><th>Ward</th><th>Community Area</th><th>FBI Code</th><th>X Coordinate</th><th>Y Coordinate</th><th>Year</th><th>Updated On</th><th>Latitude</th><th>Longitude</th><th>Location</th><th>Historical Wards 2003-2015</th><th>Zip Codes</th><th>Community Areas</th><th>Census Tracts</th><th>Wards</th><th>Boundaries - ZIP Codes</th><th>Police Districts</th><th>Police Beats</th></tr>\n",
       "<tr><td>06/18/2019 11:55:...</td><td>0484</td><td>BATTERY</td><td>PRO EMP HANDS NO/...</td><td>CTA STATION</td><td>false</td><td>false</td><td>0623</td><td>006</td><td>6</td><td>44</td><td>08B</td><td>null</td><td>null</td><td>2019</td><td>06/25/2019 04:19:...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr>\n",
       "<tr><td>06/18/2019 11:55:...</td><td>1320</td><td>CRIMINAL DAMAGE</td><td>TO VEHICLE</td><td>STREET</td><td>false</td><td>false</td><td>0821</td><td>008</td><td>14</td><td>58</td><td>14</td><td>null</td><td>null</td><td>2019</td><td>06/25/2019 04:19:...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr>\n",
       "<tr><td>06/18/2019 11:55:...</td><td>1320</td><td>CRIMINAL DAMAGE</td><td>TO VEHICLE</td><td>STREET</td><td>false</td><td>false</td><td>0821</td><td>008</td><td>14</td><td>58</td><td>14</td><td>null</td><td>null</td><td>2019</td><td>06/25/2019 04:19:...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr>\n",
       "<tr><td>06/18/2019 11:50:...</td><td>0470</td><td>PUBLIC PEACE VIOL...</td><td>RECKLESS CONDUCT</td><td>STREET</td><td>true</td><td>false</td><td>0624</td><td>006</td><td>6</td><td>69</td><td>24</td><td>null</td><td>null</td><td>2019</td><td>06/25/2019 04:19:...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr>\n",
       "<tr><td>06/18/2019 11:50:...</td><td>0460</td><td>BATTERY</td><td>SIMPLE</td><td>BAR OR TAVERN</td><td>false</td><td>false</td><td>1731</td><td>017</td><td>30</td><td>16</td><td>08B</td><td>null</td><td>null</td><td>2019</td><td>06/25/2019 04:19:...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr>\n",
       "<tr><td>06/18/2019 11:45:...</td><td>031A</td><td>ROBBERY</td><td>ARMED: HANDGUN</td><td>STREET</td><td>false</td><td>false</td><td>0524</td><td>005</td><td>34</td><td>53</td><td>03</td><td>null</td><td>null</td><td>2019</td><td>06/25/2019 04:19:...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr>\n",
       "<tr><td>06/18/2019 11:45:...</td><td>0910</td><td>MOTOR VEHICLE THEFT</td><td>AUTOMOBILE</td><td>STREET</td><td>false</td><td>false</td><td>2432</td><td>024</td><td>49</td><td>1</td><td>07</td><td>null</td><td>null</td><td>2019</td><td>06/25/2019 04:19:...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr>\n",
       "<tr><td>06/18/2019 11:39:...</td><td>1320</td><td>CRIMINAL DAMAGE</td><td>TO VEHICLE</td><td>STREET</td><td>false</td><td>false</td><td>0532</td><td>005</td><td>9</td><td>53</td><td>14</td><td>null</td><td>null</td><td>2019</td><td>06/25/2019 04:19:...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr>\n",
       "<tr><td>06/18/2019 11:32:...</td><td>051A</td><td>ASSAULT</td><td>AGGRAVATED: HANDGUN</td><td>RESIDENCE PORCH/H...</td><td>false</td><td>false</td><td>0714</td><td>007</td><td>15</td><td>67</td><td>04A</td><td>null</td><td>null</td><td>2019</td><td>06/25/2019 04:19:...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr>\n",
       "<tr><td>06/18/2019 11:30:...</td><td>0810</td><td>THEFT</td><td>OVER $500</td><td>STREET</td><td>false</td><td>false</td><td>1024</td><td>010</td><td>22</td><td>30</td><td>06</td><td>null</td><td>null</td><td>2019</td><td>06/25/2019 04:19:...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr>\n",
       "<tr><td>06/18/2019 11:30:...</td><td>0486</td><td>BATTERY</td><td>DOMESTIC BATTERY ...</td><td>RESIDENCE</td><td>false</td><td>true</td><td>0423</td><td>004</td><td>7</td><td>46</td><td>08B</td><td>null</td><td>null</td><td>2019</td><td>06/25/2019 04:19:...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr>\n",
       "<tr><td>06/18/2019 11:20:...</td><td>2022</td><td>NARCOTICS</td><td>POSS: COCAINE</td><td>STREET</td><td>true</td><td>false</td><td>0912</td><td>009</td><td>12</td><td>59</td><td>18</td><td>null</td><td>null</td><td>2019</td><td>06/25/2019 04:19:...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr>\n",
       "<tr><td>06/18/2019 11:20:...</td><td>051A</td><td>ASSAULT</td><td>AGGRAVATED: HANDGUN</td><td>APARTMENT</td><td>false</td><td>false</td><td>1011</td><td>010</td><td>24</td><td>29</td><td>04A</td><td>null</td><td>null</td><td>2019</td><td>06/25/2019 04:19:...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr>\n",
       "<tr><td>06/18/2019 11:15:...</td><td>0486</td><td>BATTERY</td><td>DOMESTIC BATTERY ...</td><td>APARTMENT</td><td>false</td><td>true</td><td>0622</td><td>006</td><td>21</td><td>71</td><td>08B</td><td>null</td><td>null</td><td>2019</td><td>06/25/2019 04:19:...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr>\n",
       "<tr><td>06/18/2019 11:15:...</td><td>0460</td><td>BATTERY</td><td>SIMPLE</td><td>SIDEWALK</td><td>false</td><td>false</td><td>0123</td><td>001</td><td>4</td><td>32</td><td>08B</td><td>null</td><td>null</td><td>2019</td><td>06/25/2019 04:19:...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr>\n",
       "<tr><td>06/18/2019 11:15:...</td><td>0460</td><td>BATTERY</td><td>SIMPLE</td><td>SIDEWALK</td><td>false</td><td>false</td><td>1533</td><td>015</td><td>28</td><td>25</td><td>08B</td><td>null</td><td>null</td><td>2019</td><td>06/25/2019 04:19:...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr>\n",
       "<tr><td>06/18/2019 11:08:...</td><td>0486</td><td>BATTERY</td><td>DOMESTIC BATTERY ...</td><td>APARTMENT</td><td>true</td><td>true</td><td>1021</td><td>010</td><td>24</td><td>29</td><td>08B</td><td>null</td><td>null</td><td>2019</td><td>06/25/2019 04:19:...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr>\n",
       "<tr><td>06/18/2019 11:08:...</td><td>4650</td><td>OTHER OFFENSE</td><td>SEX OFFENDER: FAI...</td><td>STREET</td><td>false</td><td>false</td><td>0411</td><td>004</td><td>8</td><td>45</td><td>26</td><td>null</td><td>null</td><td>2019</td><td>06/25/2019 04:19:...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr>\n",
       "<tr><td>06/18/2019 11:00:...</td><td>0460</td><td>BATTERY</td><td>SIMPLE</td><td>CTA TRAIN</td><td>false</td><td>false</td><td>1823</td><td>018</td><td>27</td><td>8</td><td>08B</td><td>null</td><td>null</td><td>2019</td><td>06/25/2019 04:19:...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr>\n",
       "<tr><td>06/18/2019 11:00:...</td><td>0330</td><td>ROBBERY</td><td>AGGRAVATED</td><td>ALLEY</td><td>false</td><td>false</td><td>0411</td><td>004</td><td>8</td><td>45</td><td>03</td><td>null</td><td>null</td><td>2019</td><td>06/25/2019 04:19:...</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "+--------------------+----+--------------------+--------------------+--------------------+------+--------+----+--------+----+--------------+--------+------------+------------+----+--------------------+--------+---------+--------+--------------------------+---------+---------------+-------------+-----+----------------------+----------------+------------+\n",
       "|                Date|IUCR|        Primary Type|         Description|Location Description|Arrest|Domestic|Beat|District|Ward|Community Area|FBI Code|X Coordinate|Y Coordinate|Year|          Updated On|Latitude|Longitude|Location|Historical Wards 2003-2015|Zip Codes|Community Areas|Census Tracts|Wards|Boundaries - ZIP Codes|Police Districts|Police Beats|\n",
       "+--------------------+----+--------------------+--------------------+--------------------+------+--------+----+--------+----+--------------+--------+------------+------------+----+--------------------+--------+---------+--------+--------------------------+---------+---------------+-------------+-----+----------------------+----------------+------------+\n",
       "|06/18/2019 11:55:...|0484|             BATTERY|PRO EMP HANDS NO/...|         CTA STATION| false|   false|0623|     006|   6|            44|     08B|        null|        null|2019|06/25/2019 04:19:...|    null|     null|    null|                      null|     null|           null|         null| null|                  null|            null|        null|\n",
       "|06/18/2019 11:55:...|1320|     CRIMINAL DAMAGE|          TO VEHICLE|              STREET| false|   false|0821|     008|  14|            58|      14|        null|        null|2019|06/25/2019 04:19:...|    null|     null|    null|                      null|     null|           null|         null| null|                  null|            null|        null|\n",
       "|06/18/2019 11:55:...|1320|     CRIMINAL DAMAGE|          TO VEHICLE|              STREET| false|   false|0821|     008|  14|            58|      14|        null|        null|2019|06/25/2019 04:19:...|    null|     null|    null|                      null|     null|           null|         null| null|                  null|            null|        null|\n",
       "|06/18/2019 11:50:...|0470|PUBLIC PEACE VIOL...|    RECKLESS CONDUCT|              STREET|  true|   false|0624|     006|   6|            69|      24|        null|        null|2019|06/25/2019 04:19:...|    null|     null|    null|                      null|     null|           null|         null| null|                  null|            null|        null|\n",
       "|06/18/2019 11:50:...|0460|             BATTERY|              SIMPLE|       BAR OR TAVERN| false|   false|1731|     017|  30|            16|     08B|        null|        null|2019|06/25/2019 04:19:...|    null|     null|    null|                      null|     null|           null|         null| null|                  null|            null|        null|\n",
       "|06/18/2019 11:45:...|031A|             ROBBERY|      ARMED: HANDGUN|              STREET| false|   false|0524|     005|  34|            53|      03|        null|        null|2019|06/25/2019 04:19:...|    null|     null|    null|                      null|     null|           null|         null| null|                  null|            null|        null|\n",
       "|06/18/2019 11:45:...|0910| MOTOR VEHICLE THEFT|          AUTOMOBILE|              STREET| false|   false|2432|     024|  49|             1|      07|        null|        null|2019|06/25/2019 04:19:...|    null|     null|    null|                      null|     null|           null|         null| null|                  null|            null|        null|\n",
       "|06/18/2019 11:39:...|1320|     CRIMINAL DAMAGE|          TO VEHICLE|              STREET| false|   false|0532|     005|   9|            53|      14|        null|        null|2019|06/25/2019 04:19:...|    null|     null|    null|                      null|     null|           null|         null| null|                  null|            null|        null|\n",
       "|06/18/2019 11:32:...|051A|             ASSAULT| AGGRAVATED: HANDGUN|RESIDENCE PORCH/H...| false|   false|0714|     007|  15|            67|     04A|        null|        null|2019|06/25/2019 04:19:...|    null|     null|    null|                      null|     null|           null|         null| null|                  null|            null|        null|\n",
       "|06/18/2019 11:30:...|0810|               THEFT|           OVER $500|              STREET| false|   false|1024|     010|  22|            30|      06|        null|        null|2019|06/25/2019 04:19:...|    null|     null|    null|                      null|     null|           null|         null| null|                  null|            null|        null|\n",
       "|06/18/2019 11:30:...|0486|             BATTERY|DOMESTIC BATTERY ...|           RESIDENCE| false|    true|0423|     004|   7|            46|     08B|        null|        null|2019|06/25/2019 04:19:...|    null|     null|    null|                      null|     null|           null|         null| null|                  null|            null|        null|\n",
       "|06/18/2019 11:20:...|2022|           NARCOTICS|       POSS: COCAINE|              STREET|  true|   false|0912|     009|  12|            59|      18|        null|        null|2019|06/25/2019 04:19:...|    null|     null|    null|                      null|     null|           null|         null| null|                  null|            null|        null|\n",
       "|06/18/2019 11:20:...|051A|             ASSAULT| AGGRAVATED: HANDGUN|           APARTMENT| false|   false|1011|     010|  24|            29|     04A|        null|        null|2019|06/25/2019 04:19:...|    null|     null|    null|                      null|     null|           null|         null| null|                  null|            null|        null|\n",
       "|06/18/2019 11:15:...|0486|             BATTERY|DOMESTIC BATTERY ...|           APARTMENT| false|    true|0622|     006|  21|            71|     08B|        null|        null|2019|06/25/2019 04:19:...|    null|     null|    null|                      null|     null|           null|         null| null|                  null|            null|        null|\n",
       "|06/18/2019 11:15:...|0460|             BATTERY|              SIMPLE|            SIDEWALK| false|   false|0123|     001|   4|            32|     08B|        null|        null|2019|06/25/2019 04:19:...|    null|     null|    null|                      null|     null|           null|         null| null|                  null|            null|        null|\n",
       "|06/18/2019 11:15:...|0460|             BATTERY|              SIMPLE|            SIDEWALK| false|   false|1533|     015|  28|            25|     08B|        null|        null|2019|06/25/2019 04:19:...|    null|     null|    null|                      null|     null|           null|         null| null|                  null|            null|        null|\n",
       "|06/18/2019 11:08:...|0486|             BATTERY|DOMESTIC BATTERY ...|           APARTMENT|  true|    true|1021|     010|  24|            29|     08B|        null|        null|2019|06/25/2019 04:19:...|    null|     null|    null|                      null|     null|           null|         null| null|                  null|            null|        null|\n",
       "|06/18/2019 11:08:...|4650|       OTHER OFFENSE|SEX OFFENDER: FAI...|              STREET| false|   false|0411|     004|   8|            45|      26|        null|        null|2019|06/25/2019 04:19:...|    null|     null|    null|                      null|     null|           null|         null| null|                  null|            null|        null|\n",
       "|06/18/2019 11:00:...|0460|             BATTERY|              SIMPLE|           CTA TRAIN| false|   false|1823|     018|  27|             8|     08B|        null|        null|2019|06/25/2019 04:19:...|    null|     null|    null|                      null|     null|           null|         null| null|                  null|            null|        null|\n",
       "|06/18/2019 11:00:...|0330|             ROBBERY|          AGGRAVATED|               ALLEY| false|   false|0411|     004|   8|            45|      03|        null|        null|2019|06/25/2019 04:19:...|    null|     null|    null|                      null|     null|           null|         null| null|                  null|            null|        null|\n",
       "+--------------------+----+--------------------+--------------------+--------------------+------+--------+----+--------+----+--------------+--------+------------+------------+----+--------------------+--------+---------+--------+--------------------------+---------+---------------+-------------+-----+----------------------+----------------+------------+\n",
       "only showing top 20 rows"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = df.drop('One')\n",
    "# df\n",
    "\n",
    "## drop multiple columns \n",
    "cols = [\"ID\", \"Case Number\", \"Block\"]\n",
    "df.drop(*cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_dvDDVtZOTYi"
   },
   "source": [
    "# Working with dates  [SparkByExamples](https://sparkbyexamples.com/pyspark/pyspark-to_date-convert-string-to-date-format/), [stackoverflow](https://stackoverflow.com/questions/38080748/convert-pyspark-string-to-date-format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "id": "eGGXo0tVQBc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|          Christmas|\n",
      "+-------------------+\n",
      "|2019-12-25 13:30:00|\n",
      "+-------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Christmas', 'string')]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = spark.createDataFrame([('2019-12-25 13:30:00',)], ['Christmas'])\n",
    "dt.show()\n",
    "dt.dtypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WkUMZnY5yc6q"
   },
   "source": [
    "## **Q : Convertir la col `Christmas`  2019-12-25 13:30:00 en `date` et en `timestamp`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>Christmas</th><th>Christmas date</th><th>Christmas timestamp</th></tr>\n",
       "<tr><td>2019-12-25 13:30:00</td><td>2019-12-25</td><td>2019-12-25 13:30:00</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-------------------+--------------+-------------------+\n",
       "|          Christmas|Christmas date|Christmas timestamp|\n",
       "+-------------------+--------------+-------------------+\n",
       "|2019-12-25 13:30:00|    2019-12-25|2019-12-25 13:30:00|\n",
       "+-------------------+--------------+-------------------+"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Le nom de la col est trop long, il faut mettre un alias (comme en SQL)\n",
    "# dt.select(F.to_date(dt.Christmas, 'yyyy-MM-dd HH:mm:ss'))  \n",
    "# dt.select(F.to_date(dt.Christmas, 'yyyy-MM-dd HH:mm:ss').alias('Christmas date'))\n",
    "\n",
    "# On s√©lectionne les cols : `Christmas`, `Christmas date`, `Christmas timestamp`\n",
    "# dt.select([\n",
    "#     dt.Christmas, \n",
    "#     F.to_date(dt.Christmas, 'yyyy-MM-dd HH:mm:ss').alias('Christmas date'), \n",
    "#     F.to_timestamp(dt.Christmas, 'yyyy-MM-dd HH:mm:ss').alias('Christmas timestamp')\n",
    "#     ])# .show(truncate=False)\n",
    "\n",
    "# Si on souhaite convertir la   \n",
    "dt.withColumn('Christmas date', F.to_date(dt.Christmas, 'yyyy-MM-dd HH:mm:ss')) \\\n",
    "    .withColumn('Christmas timestamp', F.to_timestamp(dt.Christmas, 'yyyy-MM-dd HH:mm:ss')) \n",
    "\n",
    "# dt\n",
    "# dt.dtypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r57RvNLFy1qr"
   },
   "source": [
    "## **Q : Convertir la col `Christmas`  25/Dec/2019 13:30:00 en `date` et en `timestamp`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "id": "eGGXo0tVQBc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|           Christmas|\n",
      "+--------------------+\n",
      "|25/Dec/2019 13:30:00|\n",
      "+--------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Christmas', 'string')]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = spark.createDataFrame([('25/Dec/2019 13:30:00',)], ['Christmas'])\n",
    "dt.show()\n",
    "dt.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "id": "oX5JKpxiy_dT"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>Christmas</th><th>Christmas date</th><th>Christmas timestamp</th></tr>\n",
       "<tr><td>25/Dec/2019 13:30:00</td><td>2019-12-25</td><td>2019-12-25 13:30:00</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------------------+--------------+-------------------+\n",
       "|           Christmas|Christmas date|Christmas timestamp|\n",
       "+--------------------+--------------+-------------------+\n",
       "|25/Dec/2019 13:30:00|    2019-12-25|2019-12-25 13:30:00|\n",
       "+--------------------+--------------+-------------------+"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.withColumn('Christmas date', F.to_date(dt.Christmas, 'dd/MMM/yyyy HH:mm:ss')) \\\n",
    "    .withColumn('Christmas timestamp', F.to_timestamp(dt.Christmas, 'dd/MMM/yyyy HH:mm:ss')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r57RvNLFy1qr"
   },
   "source": [
    "## **Q : Convertir la col `Christmas`  12/25/2019 01:30:00 PM en `date` et en `timestamp`  [stackoverflow](https://stackoverflow.com/questions/51680587/how-can-i-account-for-am-pm-in-string-to-datetime-conversion-in-pyspark)** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "id": "eGGXo0tVQBc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+\n",
      "|Christmas             |\n",
      "+----------------------+\n",
      "|12/25/2019 01:30:00 PM|\n",
      "+----------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Christmas', 'string')]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# La sp√©cificit√© ici est que la date comporte AM/PM\n",
    "dt = spark.createDataFrame([('12/25/2019 01:30:00 PM', )], ['Christmas'])\n",
    "dt.show(truncate=False)\n",
    "dt.dtypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hgnCWSfNZsLV"
   },
   "source": [
    "## **Q : Convertir la col `Date` du `df` et trouver combien de crimes ont √©t√© commis `12-Nov-2018` ?** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.select(df.Date).show(truncate=False)\n",
    "# df.select(df.Date).dtypes # string\n",
    "\n",
    "## Convertir la column `Date` ? \n",
    "# df = df.withColumn('Date_', F.to_timestamp(df.Date, 'MM/dd/yyy hh:mm:ss a'))\n",
    "\n",
    "df.select(df.Date_).dtypes # timestamp\n",
    "\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wIeoX7GeOTYf",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/01/17 21:48:13 WARN MemoryStore: Not enough space to cache rdd_21_5 in memory! (computed 21.0 MiB so far)\n",
      "22/01/17 21:48:13 WARN MemoryStore: Not enough space to cache rdd_21_8 in memory! (computed 21.5 MiB so far)\n",
      "22/01/17 21:48:13 WARN MemoryStore: Not enough space to cache rdd_21_6 in memory! (computed 21.3 MiB so far)\n",
      "22/01/17 21:48:13 WARN MemoryStore: Not enough space to cache rdd_21_7 in memory! (computed 21.5 MiB so far)\n",
      "22/01/17 21:48:18 WARN MemoryStore: Not enough space to cache rdd_21_9 in memory! (computed 21.5 MiB so far)\n",
      "22/01/17 21:48:18 WARN MemoryStore: Not enough space to cache rdd_21_10 in memory! (computed 21.3 MiB so far)\n",
      "22/01/17 21:48:18 WARN MemoryStore: Not enough space to cache rdd_21_11 in memory! (computed 21.3 MiB so far)\n",
      "22/01/17 21:48:18 WARN MemoryStore: Not enough space to cache rdd_21_12 in memory! (computed 21.4 MiB so far)\n",
      "22/01/17 21:48:29 WARN MemoryStore: Not enough space to cache rdd_21_6 in memory! (computed 21.3 MiB so far)\n",
      "22/01/17 21:48:29 WARN MemoryStore: Not enough space to cache rdd_21_5 in memory! (computed 21.0 MiB so far)\n",
      "22/01/17 21:48:29 WARN MemoryStore: Not enough space to cache rdd_21_8 in memory! (computed 21.5 MiB so far)\n",
      "22/01/17 21:48:29 WARN MemoryStore: Not enough space to cache rdd_21_7 in memory! (computed 21.5 MiB so far)\n",
      "22/01/17 21:48:34 WARN MemoryStore: Not enough space to cache rdd_21_9 in memory! (computed 21.5 MiB so far)\n",
      "22/01/17 21:48:34 WARN MemoryStore: Not enough space to cache rdd_21_10 in memory! (computed 21.3 MiB so far)\n",
      "22/01/17 21:48:34 WARN MemoryStore: Not enough space to cache rdd_21_11 in memory! (computed 21.3 MiB so far)\n",
      "22/01/17 21:48:34 WARN MemoryStore: Not enough space to cache rdd_21_12 in memory! (computed 21.4 MiB so far)\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>ID</th><th>Case Number</th><th>Date</th><th>Block</th><th>IUCR</th><th>Primary Type</th><th>Description</th><th>Location Description</th><th>Arrest</th><th>Domestic</th><th>Beat</th><th>District</th><th>Ward</th><th>Community Area</th><th>FBI Code</th><th>X Coordinate</th><th>Y Coordinate</th><th>Year</th><th>Updated On</th><th>Latitude</th><th>Longitude</th><th>Location</th><th>Historical Wards 2003-2015</th><th>Zip Codes</th><th>Community Areas</th><th>Census Tracts</th><th>Wards</th><th>Boundaries - ZIP Codes</th><th>Police Districts</th><th>Police Beats</th><th>Date_</th></tr>\n",
       "<tr><td>11505149</td><td>JB513151</td><td>11/12/2018 12:00:...</td><td>003XX S WHIPPLE ST</td><td>0810</td><td>THEFT</td><td>OVER $500</td><td>STREET</td><td>false</td><td>false</td><td>1124</td><td>11</td><td>28</td><td>27</td><td>06</td><td>1156099</td><td>1898319</td><td>2018</td><td>11/19/2018 04:22:...</td><td>41.876776356</td><td>-87.702317641</td><td>(41.876776356, -8...</td><td>11</td><td>21184</td><td>28</td><td>737</td><td>23</td><td>28</td><td>16</td><td>123</td><td>2018-11-12 00:00:00</td></tr>\n",
       "<tr><td>11516594</td><td>JB528186</td><td>11/12/2018 12:00:...</td><td>049XX S PRAIRIE AVE</td><td>2826</td><td>OTHER OFFENSE</td><td>HARASSMENT BY ELE...</td><td>OTHER</td><td>false</td><td>false</td><td>224</td><td>2</td><td>3</td><td>38</td><td>26</td><td>1178879</td><td>1872259</td><td>2018</td><td>11/28/2018 04:14:...</td><td>41.804775828</td><td>-87.619472488</td><td>(41.804775828, -8...</td><td>12</td><td>21192</td><td>4</td><td>449</td><td>9</td><td>10</td><td>24</td><td>107</td><td>2018-11-12 00:00:00</td></tr>\n",
       "<tr><td>11540042</td><td>JB559262</td><td>11/12/2018 12:00:...</td><td>010XX N DEARBORN ST</td><td>1140</td><td>DECEPTIVE PRACTICE</td><td>EMBEZZLEMENT</td><td>CONVENIENCE STORE</td><td>true</td><td>false</td><td>1824</td><td>18</td><td>2</td><td>8</td><td>12</td><td>1175747</td><td>1907348</td><td>2018</td><td>03/16/2019 04:01:...</td><td>41.901133376</td><td>-87.629904979</td><td>(41.901133376, -8...</td><td>22</td><td>14926</td><td>37</td><td>230</td><td>11</td><td>54</td><td>14</td><td>197</td><td>2018-11-12 00:00:00</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------+-----------+--------------------+-------------------+----+------------------+--------------------+--------------------+------+--------+----+--------+----+--------------+--------+------------+------------+----+--------------------+------------+-------------+--------------------+--------------------------+---------+---------------+-------------+-----+----------------------+----------------+------------+-------------------+\n",
       "|      ID|Case Number|                Date|              Block|IUCR|      Primary Type|         Description|Location Description|Arrest|Domestic|Beat|District|Ward|Community Area|FBI Code|X Coordinate|Y Coordinate|Year|          Updated On|    Latitude|    Longitude|            Location|Historical Wards 2003-2015|Zip Codes|Community Areas|Census Tracts|Wards|Boundaries - ZIP Codes|Police Districts|Police Beats|              Date_|\n",
       "+--------+-----------+--------------------+-------------------+----+------------------+--------------------+--------------------+------+--------+----+--------+----+--------------+--------+------------+------------+----+--------------------+------------+-------------+--------------------+--------------------------+---------+---------------+-------------+-----+----------------------+----------------+------------+-------------------+\n",
       "|11505149|   JB513151|11/12/2018 12:00:...| 003XX S WHIPPLE ST|0810|             THEFT|           OVER $500|              STREET| false|   false|1124|      11|  28|            27|      06|     1156099|     1898319|2018|11/19/2018 04:22:...|41.876776356|-87.702317641|(41.876776356, -8...|                        11|    21184|             28|          737|   23|                    28|              16|         123|2018-11-12 00:00:00|\n",
       "|11516594|   JB528186|11/12/2018 12:00:...|049XX S PRAIRIE AVE|2826|     OTHER OFFENSE|HARASSMENT BY ELE...|               OTHER| false|   false| 224|       2|   3|            38|      26|     1178879|     1872259|2018|11/28/2018 04:14:...|41.804775828|-87.619472488|(41.804775828, -8...|                        12|    21192|              4|          449|    9|                    10|              24|         107|2018-11-12 00:00:00|\n",
       "|11540042|   JB559262|11/12/2018 12:00:...|010XX N DEARBORN ST|1140|DECEPTIVE PRACTICE|        EMBEZZLEMENT|   CONVENIENCE STORE|  true|   false|1824|      18|   2|             8|      12|     1175747|     1907348|2018|03/16/2019 04:01:...|41.901133376|-87.629904979|(41.901133376, -8...|                        22|    14926|             37|          230|   11|                    54|              14|         197|2018-11-12 00:00:00|\n",
       "+--------+-----------+--------------------+-------------------+----+------------------+--------------------+--------------------+------+--------+----+--------+----+--------------+--------+------------+------------+----+--------------------+------------+-------------+--------------------+--------------------------+---------+---------------+-------------+-----+----------------------+----------------+------------+-------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# On ex√©cute la Qry sur la col `Date` (string) pr trouver combien de jours qui corresp. √† `2018-11-12`\n",
    "# Att. la Qry va mettre 2min et retourne 0 obs  \n",
    "# df.filter(df.Date == F.lit('2018-11-12'))\n",
    "\n",
    "# On ex√©cute maintenant la Qry sur la col `Date_` (timestamp)\n",
    "# Att. la Qry va mettre 2min et retourne 3 obs  \n",
    "\n",
    "df.filter(df.Date_ == F.lit('2018-11-12'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "id": "oX5JKpxiy_dT"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>Christmas</th><th>Christmas date</th><th>Christmas timestamp</th></tr>\n",
       "<tr><td>12/25/2019 01:30:...</td><td>2019-12-25</td><td>2019-12-25 13:30:00</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------------------+--------------+-------------------+\n",
       "|           Christmas|Christmas date|Christmas timestamp|\n",
       "+--------------------+--------------+-------------------+\n",
       "|12/25/2019 01:30:...|    2019-12-25|2019-12-25 13:30:00|\n",
       "+--------------------+--------------+-------------------+"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.withColumn('Christmas date', F.to_date(dt.Christmas, 'MM/dd/yyyy hh:mm:ss a')) \\\n",
    "  .withColumn('Christmas timestamp', F.to_timestamp(dt.Christmas, 'MM/dd/yyyy hh:mm:ss a')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qjh1t1XamJ-E"
   },
   "source": [
    "## **Q : What is 3 days earlier that the oldest date and 3 days later than the most recent date?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "YbSNtcMSQAiH"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Date_', 'timestamp')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LDPZP60-OTYf"
   },
   "source": [
    "# **Working with rows**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9W-rzQcbOTYf"
   },
   "source": [
    "**Q : What are the top 10 number of reported crimes by Primary type, in descending order of occurence?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "xflCxlerOTYg"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/01/17 22:16:10 WARN MemoryStore: Not enough space to cache rdd_21_1 in memory! (computed 21.5 MiB so far)\n",
      "22/01/17 22:16:10 WARN MemoryStore: Not enough space to cache rdd_21_5 in memory! (computed 1262.6 KiB so far)\n",
      "22/01/17 22:16:10 WARN MemoryStore: Not enough space to cache rdd_21_3 in memory! (computed 21.0 MiB so far)\n",
      "22/01/17 22:16:10 WARN MemoryStore: Not enough space to cache rdd_21_4 in memory! (computed 21.3 MiB so far)\n",
      "22/01/17 22:16:10 WARN MemoryStore: Not enough space to cache rdd_21_6 in memory! (computed 21.3 MiB so far)\n",
      "22/01/17 22:16:10 WARN MemoryStore: Not enough space to cache rdd_21_7 in memory! (computed 21.5 MiB so far)\n",
      "22/01/17 22:16:10 WARN MemoryStore: Not enough space to cache rdd_21_9 in memory! (computed 21.5 MiB so far)\n",
      "22/01/17 22:16:10 WARN MemoryStore: Not enough space to cache rdd_21_10 in memory! (computed 21.3 MiB so far)\n",
      "22/01/17 22:16:11 WARN MemoryStore: Not enough space to cache rdd_21_4 in memory! (computed 1279.3 KiB so far)\n",
      "22/01/17 22:16:11 WARN MemoryStore: Not enough space to cache rdd_21_1 in memory! (computed 21.5 MiB so far)\n",
      "22/01/17 22:16:11 WARN MemoryStore: Not enough space to cache rdd_21_3 in memory! (computed 21.0 MiB so far)\n",
      "22/01/17 22:16:11 WARN MemoryStore: Not enough space to cache rdd_21_5 in memory! (computed 21.0 MiB so far)\n",
      "22/01/17 22:16:11 WARN MemoryStore: Not enough space to cache rdd_21_6 in memory! (computed 21.3 MiB so far)\n",
      "22/01/17 22:16:11 WARN MemoryStore: Not enough space to cache rdd_21_9 in memory! (computed 1297.2 KiB so far)\n",
      "22/01/17 22:16:11 WARN MemoryStore: Not enough space to cache rdd_21_7 in memory! (computed 21.5 MiB so far)\n",
      "22/01/17 22:16:11 WARN MemoryStore: Not enough space to cache rdd_21_10 in memory! (computed 21.3 MiB so far)\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "27.602098565931637"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/01/18 02:48:18 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 152756 ms exceeds timeout 120000 ms\n",
      "22/01/18 02:48:18 WARN SparkContext: Killing executors is not supported by current scheduler.\n"
     ]
    }
   ],
   "source": [
    "# df.select('Arrest').distinct().show()\n",
    "# df.select('Arrest').dtypes # boolean\n",
    "(df.filter(df.Arrest == 'true').count() / df.select(df.Arrest).count())* 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HxSVEoOIOTYg"
   },
   "source": [
    "# Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "usW6fEsyOTYg"
   },
   "source": [
    "**Q : What percentage of reported crimes resulted in an arrest?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KHYsOrsiOTYg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5PZn1E1uOTYg"
   },
   "source": [
    "**Q : What are the top 3 locations for reported crimes?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IH-DApWoOTYg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f62roeF4OTYh"
   },
   "source": [
    "# Built-in functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "808f1HzwgDyh"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PeeOFy5cgDRq"
   },
   "outputs": [],
   "source": [
    "print(dir(functions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1yL-b-swunTM"
   },
   "source": [
    "## String functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rHp9A7wyp1L4"
   },
   "source": [
    "**Q : Display the Primary Type column in lower and upper characters, and the first 4 characters of the column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4HNqGQKCqE9K"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZYDsLbbrf6dK"
   },
   "source": [
    "## Numeric functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H5CZwvAwhpCx"
   },
   "source": [
    "**Q : Show the oldest date and the most recent date**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oP8NWAiUuSJC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GUCYsfeKOTYj"
   },
   "source": [
    "# Working with joins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5klVM9jJZBDl"
   },
   "source": [
    "**Q : Download police station data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Dp1xLQ6OTYk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CdBqB9Oiw0gV"
   },
   "source": [
    "**Q : The reported crimes dataset has only the district number. Add the district name by joining with the police station dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3HBJev2Ctdbo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4fuz-qgTOTYk"
   },
   "source": [
    "# Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WqQFeYeuOTYk"
   },
   "source": [
    "**Q : What is the most frequently reported non-criminal activity?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5CJlKstuOTYk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iBP4HTQDOTYk"
   },
   "source": [
    "**Q : Using a bar chart, plot which day of the week has the most number of reported crime.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ugRDxNwNgHNa"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lire √† partir de HDFS\n",
    "[SparkByExamples](https://sparkbyexamples.com/spark/spark-read-write-files-from-hdfs-txt-csv-avro-parquet-json/), [saggie](https://saagie.zendesk.com/hc/en-us/articles/360029759552-PySpark-Read-and-Write-Files-from-HDFS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drwxr-xr-x   - sayf supergroup          0 2021-09-09 16:35 /hadoop\n",
      "-rw-r--r--   3 sayf supergroup  504941532 2021-09-09 16:35 /hadoop/access_log\n",
      "drwxr-xr-x   - sayf supergroup          0 2021-12-24 02:11 /user\n",
      "drwxr-xr-x   - sayf supergroup          0 2021-12-24 02:05 /user/sayf\n",
      "drwxr-xr-x   - sayf supergroup          0 2021-12-24 02:05 /user/sayf/data\n",
      "drwxr-xr-x   - sayf supergroup          0 2021-12-24 02:11 /user/spark\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls -R /"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.223.157.186 - - [15/Jul/2009:14:58:59 -0700] \"GET / HTTP/1.1\" 403 202\n",
      "10.223.157.186 - - [15/Jul/2009:14:58:59 -0700] \"GET /favicon.ico HTTP/1.1\" 404 \n",
      "209\n",
      "10.223.157.186 - - [15/Jul/2009:15:50:35 -0700] \"GET / HTTP/1.1\" 200 9157\n",
      "10.223.157.186 - - [15/Jul/2009:15:50:35 -0700] \"GET /assets/js/lowpro.js HTTP/1\n",
      ".1\" 200 10469\n",
      "10.223.157.186 - - [15/Jul/2009:15:50:35 -0700] \"GET /assets/css/reset.css HTTP/\n",
      "1.1\" 200 1014\n",
      "10.223.157.186 - - [15/Jul/2009:15:50:35 -0700] \"GET /assets/css/960.css HTTP/1.\n",
      "1\" 200 6206\n",
      "10.223.157.186 - - [15/Jul/2009:15:50:35 -0700] \"GET /assets/css/the-associates.\n",
      "css HTTP/1.1\" 200 15779\n",
      "10.223.157.186 - - [15/Jul/2009:15:50:35 -0700] \"GET /assets/js/the-associates.j\n",
      "s HTTP/1.1\" 200 4492\n",
      "10.223.157.186 - - [15/Jul/2009:15:50:35 -0700] \"GET /assets/js/lightbox.js HTTP\n",
      "/1.1\" 200 25960\n",
      "10.223.157.186 - - [15/Jul/2009:15:50:36 -0700] \"GET /assets/img/search-button.g\n",
      "if HTTP/1.1\" 200 168\n",
      "10.223.157.186 - - [15/Jul/2009:15:50:36 -0700] \"GET /assets/img/dummy/secondary\n",
      "-news-3.jpg HTTP/1.1\" 200 5604\n",
      "10.223.157.186 - - [15/Jul/2009:15:50:36 -0700] \"GET /assets/img/dummy/primary-n\n",
      "ews-1.jpg HTTP/1.1\" 200 10556\n",
      "10.223.157.186 - - [15/Jul/2009:15:50:36 -0700] \"GET /assets/img/dummy/primary-n\n",
      "\u001B[Kcat: Unable to write to output stream.\n"
     ]
    }
   ],
   "source": [
    "# Le sep est un espace\n",
    "!hdfs dfs -cat /hadoop/access_log | more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---+---+---------------------+------+---------------------------------------------------------+---+-----+\n",
      "|_c0           |_c1|_c2|_c3                  |_c4   |_c5                                                      |_c6|_c7  |\n",
      "+--------------+---+---+---------------------+------+---------------------------------------------------------+---+-----+\n",
      "|10.223.157.186|-  |-  |[15/Jul/2009:14:58:59|-0700]|GET / HTTP/1.1                                           |403|202  |\n",
      "|10.223.157.186|-  |-  |[15/Jul/2009:14:58:59|-0700]|GET /favicon.ico HTTP/1.1                                |404|209  |\n",
      "|10.223.157.186|-  |-  |[15/Jul/2009:15:50:35|-0700]|GET / HTTP/1.1                                           |200|9157 |\n",
      "|10.223.157.186|-  |-  |[15/Jul/2009:15:50:35|-0700]|GET /assets/js/lowpro.js HTTP/1.1                        |200|10469|\n",
      "|10.223.157.186|-  |-  |[15/Jul/2009:15:50:35|-0700]|GET /assets/css/reset.css HTTP/1.1                       |200|1014 |\n",
      "|10.223.157.186|-  |-  |[15/Jul/2009:15:50:35|-0700]|GET /assets/css/960.css HTTP/1.1                         |200|6206 |\n",
      "|10.223.157.186|-  |-  |[15/Jul/2009:15:50:35|-0700]|GET /assets/css/the-associates.css HTTP/1.1              |200|15779|\n",
      "|10.223.157.186|-  |-  |[15/Jul/2009:15:50:35|-0700]|GET /assets/js/the-associates.js HTTP/1.1                |200|4492 |\n",
      "|10.223.157.186|-  |-  |[15/Jul/2009:15:50:35|-0700]|GET /assets/js/lightbox.js HTTP/1.1                      |200|25960|\n",
      "|10.223.157.186|-  |-  |[15/Jul/2009:15:50:36|-0700]|GET /assets/img/search-button.gif HTTP/1.1               |200|168  |\n",
      "|10.223.157.186|-  |-  |[15/Jul/2009:15:50:36|-0700]|GET /assets/img/dummy/secondary-news-3.jpg HTTP/1.1      |200|5604 |\n",
      "|10.223.157.186|-  |-  |[15/Jul/2009:15:50:36|-0700]|GET /assets/img/dummy/primary-news-1.jpg HTTP/1.1        |200|10556|\n",
      "|10.223.157.186|-  |-  |[15/Jul/2009:15:50:36|-0700]|GET /assets/img/dummy/primary-news-2.jpg HTTP/1.1        |200|9925 |\n",
      "|10.223.157.186|-  |-  |[15/Jul/2009:15:50:36|-0700]|GET /assets/img/closelabel.gif HTTP/1.1                  |200|979  |\n",
      "|10.223.157.186|-  |-  |[15/Jul/2009:15:50:36|-0700]|GET /assets/img/home-logo.png HTTP/1.1                   |200|3892 |\n",
      "|10.223.157.186|-  |-  |[15/Jul/2009:15:50:36|-0700]|GET /assets/img/dummy/secondary-news-2.jpg HTTP/1.1      |200|5397 |\n",
      "|10.223.157.186|-  |-  |[15/Jul/2009:15:50:36|-0700]|GET /assets/img/loading.gif HTTP/1.1                     |200|2767 |\n",
      "|10.223.157.186|-  |-  |[15/Jul/2009:15:50:36|-0700]|GET /assets/img/dummy/secondary-news-4.jpg HTTP/1.1      |200|5766 |\n",
      "|10.223.157.186|-  |-  |[15/Jul/2009:15:50:36|-0700]|GET /assets/img/home-media-block-placeholder.jpg HTTP/1.1|200|68831|\n",
      "|10.223.157.186|-  |-  |[15/Jul/2009:15:50:37|-0700]|GET /assets/img/dummy/secondary-news-1.jpg HTTP/1.1      |200|5766 |\n",
      "+--------------+---+---+---------------------+------+---------------------------------------------------------+---+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# df_log = spark.read.csv('hdfs://localhost:8020/hadoop/access_log', sep=' ')\n",
    "df_log.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ecrire dans HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Create data\n",
    "test_write = [('First', 1), ('Second', 2), ('Third', 3), ('Fourth', 4), ('Fifth', 5)]\n",
    "test_write = spark.createDataFrame(test_write)\n",
    "\n",
    "# Write into HDFS\n",
    "test_write.write.csv(\"hdfs://localhost:8020/hadoop/test_write.csv\", mode = 'overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drwxr-xr-x   - sayf supergroup          0 2021-12-28 03:03 /hadoop\n",
      "-rw-r--r--   3 sayf supergroup  504941532 2021-09-09 16:35 /hadoop/access_log\n",
      "drwxr-xr-x   - sayf supergroup          0 2021-12-28 03:03 /hadoop/test_write.csv\n",
      "-rw-r--r--   3 sayf supergroup          0 2021-12-28 03:03 /hadoop/test_write.csv/_SUCCESS\n",
      "-rw-r--r--   3 sayf supergroup          8 2021-12-28 03:03 /hadoop/test_write.csv/part-00000-b613feb4-0e29-42e6-a2ec-fa6949d01a7d-c000.csv\n",
      "-rw-r--r--   3 sayf supergroup          9 2021-12-28 03:03 /hadoop/test_write.csv/part-00001-b613feb4-0e29-42e6-a2ec-fa6949d01a7d-c000.csv\n",
      "-rw-r--r--   3 sayf supergroup          8 2021-12-28 03:03 /hadoop/test_write.csv/part-00002-b613feb4-0e29-42e6-a2ec-fa6949d01a7d-c000.csv\n",
      "-rw-r--r--   3 sayf supergroup         17 2021-12-28 03:03 /hadoop/test_write.csv/part-00003-b613feb4-0e29-42e6-a2ec-fa6949d01a7d-c000.csv\n",
      "drwxr-xr-x   - sayf supergroup          0 2021-12-24 02:11 /user\n",
      "drwxr-xr-x   - sayf supergroup          0 2021-12-24 02:05 /user/sayf\n",
      "drwxr-xr-x   - sayf supergroup          0 2021-12-24 02:05 /user/sayf/data\n",
      "drwxr-xr-x   - sayf supergroup          0 2021-12-24 02:11 /user/spark\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls -R /"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "4-Colab_Install_Spark_Process_Data.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "e774977668b7c0ae8309835a5187aa7fbf7669e7d0bb59755bc63e573643edcd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
